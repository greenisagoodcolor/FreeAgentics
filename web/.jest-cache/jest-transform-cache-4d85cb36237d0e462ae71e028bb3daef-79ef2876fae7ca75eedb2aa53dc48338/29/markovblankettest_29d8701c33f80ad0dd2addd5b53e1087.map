{"version":3,"sources":["/Users/matthewmoroney/builds/FreeAgentics/web/__tests__/lib/markov-blanket.test.ts"],"sourcesContent":["/**\n * Markov Blanket Tests\n *\n * Tests for Markov blanket calculations, configurations, and state management\n * following ADR-007 comprehensive testing requirements.\n */\n\nimport {\n  MarkovBlanket,\n  MarkovBlanketState,\n  createMarkovBlanket,\n  updateMarkovBlanket,\n  calculateFreeEnergy,\n  minimizeFreeEnergy,\n  getMarkovBlanketNeighbors,\n  mergeMarkovBlankets,\n  validateMarkovBlanket,\n  MarkovBlanketConfig,\n  SensorState,\n  ActiveState,\n  InternalState,\n  ExternalState,\n} from \"@/lib/markov-blanket\";\n\ndescribe(\"Markov Blanket Core\", () => {\n  let testBlanket: MarkovBlanket;\n\n  beforeEach(() => {\n    testBlanket = createMarkovBlanket({\n      id: \"test-blanket-1\",\n      agentId: \"agent-1\",\n      sensorStates: {\n        visual: { value: 0.5, confidence: 0.8 },\n        auditory: { value: 0.3, confidence: 0.9 },\n      },\n      activeStates: {\n        movement: { value: 0.7, energy: 0.6 },\n        communication: { value: 0.4, energy: 0.8 },\n      },\n      internalStates: {\n        belief_exploration: 0.6,\n        belief_cooperation: 0.8,\n        energy_level: 0.75,\n      },\n      externalStates: {\n        environment_complexity: 0.4,\n        agent_density: 0.3,\n        resource_availability: 0.7,\n      },\n    });\n  });\n\n  describe(\"Creation and Initialization\", () => {\n    it(\"creates a valid Markov blanket\", () => {\n      expect(testBlanket).toMatchObject({\n        id: \"test-blanket-1\",\n        agentId: \"agent-1\",\n        sensorStates: expect.any(Object),\n        activeStates: expect.any(Object),\n        internalStates: expect.any(Object),\n        externalStates: expect.any(Object),\n      });\n    });\n\n    it(\"validates required fields\", () => {\n      expect(() => {\n        createMarkovBlanket({\n          id: \"\",\n          agentId: \"agent-1\",\n          sensorStates: {},\n          activeStates: {},\n          internalStates: {},\n          externalStates: {},\n        });\n      }).toThrow(\"Invalid Markov blanket configuration\");\n    });\n\n    it(\"initializes with default values when not provided\", () => {\n      const minimalBlanket = createMarkovBlanket({\n        id: \"minimal-1\",\n        agentId: \"agent-2\",\n      });\n\n      expect(minimalBlanket.sensorStates).toBeDefined();\n      expect(minimalBlanket.activeStates).toBeDefined();\n      expect(minimalBlanket.internalStates).toBeDefined();\n      expect(minimalBlanket.externalStates).toBeDefined();\n    });\n\n    it(\"preserves custom configuration\", () => {\n      const config: MarkovBlanketConfig = {\n        learningRate: 0.01,\n        precision: 0.001,\n        maxIterations: 1000,\n        convergenceThreshold: 0.0001,\n      };\n\n      const blanketWithConfig = createMarkovBlanket({\n        id: \"config-1\",\n        agentId: \"agent-3\",\n        config,\n      });\n\n      expect(blanketWithConfig.config).toMatchObject(config);\n    });\n  });\n\n  describe(\"State Updates\", () => {\n    it(\"updates sensor states\", () => {\n      const updated = updateMarkovBlanket(testBlanket, {\n        sensorStates: {\n          visual: { value: 0.8, confidence: 0.9 },\n          tactile: { value: 0.2, confidence: 0.7 },\n        },\n      });\n\n      expect(updated.sensorStates.visual).toMatchObject({\n        value: 0.8,\n        confidence: 0.9,\n      });\n      expect(updated.sensorStates.tactile).toBeDefined();\n      expect(updated.sensorStates.auditory).toBeUndefined();\n    });\n\n    it(\"updates active states with energy constraints\", () => {\n      const updated = updateMarkovBlanket(testBlanket, {\n        activeStates: {\n          movement: { value: 0.9, energy: 0.1 },\n        },\n      });\n\n      // Should respect energy constraints\n      expect(updated.activeStates.movement.value).toBeLessThanOrEqual(0.9);\n      expect(updated.activeStates.movement.energy).toBeGreaterThanOrEqual(0);\n    });\n\n    it(\"updates internal states with normalization\", () => {\n      const updated = updateMarkovBlanket(testBlanket, {\n        internalStates: {\n          belief_exploration: 1.5, // Should be normalized\n          belief_cooperation: -0.2, // Should be clamped\n        },\n      });\n\n      expect(updated.internalStates.belief_exploration).toBeLessThanOrEqual(1);\n      expect(updated.internalStates.belief_cooperation).toBeGreaterThanOrEqual(\n        0,\n      );\n    });\n\n    it(\"triggers recalculation on state change\", () => {\n      const initialFreeEnergy = testBlanket.freeEnergy;\n\n      const updated = updateMarkovBlanket(testBlanket, {\n        internalStates: {\n          belief_exploration: 0.9,\n        },\n      });\n\n      expect(updated.freeEnergy).not.toBe(initialFreeEnergy);\n      expect(updated.lastUpdated).toBeGreaterThan(testBlanket.lastUpdated);\n    });\n  });\n\n  describe(\"Free Energy Calculations\", () => {\n    it(\"calculates free energy correctly\", () => {\n      const freeEnergy = calculateFreeEnergy(testBlanket);\n\n      expect(freeEnergy).toBeGreaterThan(0);\n      expect(Number.isFinite(freeEnergy)).toBe(true);\n    });\n\n    it(\"increases with prediction error\", () => {\n      const lowErrorBlanket = updateMarkovBlanket(testBlanket, {\n        sensorStates: {\n          visual: { value: 0.5, confidence: 0.95 },\n        },\n        internalStates: {\n          belief_visual: 0.48, // Close to sensory value\n        },\n      });\n\n      const highErrorBlanket = updateMarkovBlanket(testBlanket, {\n        sensorStates: {\n          visual: { value: 0.5, confidence: 0.95 },\n        },\n        internalStates: {\n          belief_visual: 0.1, // Far from sensory value\n        },\n      });\n\n      const lowFE = calculateFreeEnergy(lowErrorBlanket);\n      const highFE = calculateFreeEnergy(highErrorBlanket);\n\n      expect(highFE).toBeGreaterThan(lowFE);\n    });\n\n    it(\"includes entropy terms\", () => {\n      const certainBlanket = updateMarkovBlanket(testBlanket, {\n        internalStates: {\n          belief_exploration: 0.99,\n          belief_cooperation: 0.01,\n        },\n      });\n\n      const uncertainBlanket = updateMarkovBlanket(testBlanket, {\n        internalStates: {\n          belief_exploration: 0.5,\n          belief_cooperation: 0.5,\n        },\n      });\n\n      const certainFE = calculateFreeEnergy(certainBlanket);\n      const uncertainFE = calculateFreeEnergy(uncertainBlanket);\n\n      // Higher entropy (uncertainty) should contribute to free energy\n      expect(Math.abs(certainFE - uncertainFE)).toBeGreaterThan(0.01);\n    });\n\n    it(\"handles edge cases\", () => {\n      const edgeCaseBlanket = createMarkovBlanket({\n        id: \"edge-1\",\n        agentId: \"agent-edge\",\n        internalStates: {\n          zero_state: 0,\n          one_state: 1,\n        },\n      });\n\n      const freeEnergy = calculateFreeEnergy(edgeCaseBlanket);\n      expect(Number.isFinite(freeEnergy)).toBe(true);\n      expect(freeEnergy).not.toBeNaN();\n    });\n  });\n\n  describe(\"Free Energy Minimization\", () => {\n    it(\"reduces free energy through optimization\", async () => {\n      const initialFE = calculateFreeEnergy(testBlanket);\n      const optimized = await minimizeFreeEnergy(testBlanket);\n      const finalFE = calculateFreeEnergy(optimized);\n\n      expect(finalFE).toBeLessThanOrEqual(initialFE);\n    });\n\n    it(\"converges within iteration limit\", async () => {\n      const optimized = await minimizeFreeEnergy(testBlanket, {\n        maxIterations: 100,\n        convergenceThreshold: 0.001,\n      });\n\n      expect(optimized.convergenceInfo).toBeDefined();\n      expect(optimized.convergenceInfo.iterations).toBeLessThanOrEqual(100);\n    });\n\n    it(\"respects learning rate\", async () => {\n      const slowOptimized = await minimizeFreeEnergy(testBlanket, {\n        learningRate: 0.001,\n        maxIterations: 10,\n      });\n\n      const fastOptimized = await minimizeFreeEnergy(testBlanket, {\n        learningRate: 0.1,\n        maxIterations: 10,\n      });\n\n      const slowChange = Math.abs(\n        calculateFreeEnergy(slowOptimized) - calculateFreeEnergy(testBlanket),\n      );\n      const fastChange = Math.abs(\n        calculateFreeEnergy(fastOptimized) - calculateFreeEnergy(testBlanket),\n      );\n\n      expect(fastChange).toBeGreaterThan(slowChange);\n    });\n\n    it(\"maintains state constraints during optimization\", async () => {\n      const optimized = await minimizeFreeEnergy(testBlanket);\n\n      // Check all states are within valid ranges\n      Object.values(optimized.internalStates).forEach((value) => {\n        expect(value).toBeGreaterThanOrEqual(0);\n        expect(value).toBeLessThanOrEqual(1);\n      });\n\n      Object.values(optimized.activeStates).forEach((state) => {\n        expect(state.value).toBeGreaterThanOrEqual(0);\n        expect(state.value).toBeLessThanOrEqual(1);\n        expect(state.energy).toBeGreaterThanOrEqual(0);\n      });\n    });\n  });\n\n  describe(\"Markov Blanket Neighbors\", () => {\n    it(\"identifies neighboring blankets\", () => {\n      const blankets = [\n        testBlanket,\n        createMarkovBlanket({\n          id: \"neighbor-1\",\n          agentId: \"agent-2\",\n          externalStates: {\n            proximity_to_agent1: 0.9,\n          },\n        }),\n        createMarkovBlanket({\n          id: \"distant-1\",\n          agentId: \"agent-3\",\n          externalStates: {\n            proximity_to_agent1: 0.1,\n          },\n        }),\n      ];\n\n      const neighbors = getMarkovBlanketNeighbors(testBlanket, blankets, {\n        proximityThreshold: 0.5,\n      });\n\n      expect(neighbors).toHaveLength(1);\n      expect(neighbors[0].id).toBe(\"neighbor-1\");\n    });\n\n    it(\"considers multiple interaction factors\", () => {\n      const blankets = [\n        testBlanket,\n        createMarkovBlanket({\n          id: \"interacting-1\",\n          agentId: \"agent-2\",\n          activeStates: {\n            communication: { value: 0.8, energy: 0.7 },\n          },\n        }),\n      ];\n\n      const neighbors = getMarkovBlanketNeighbors(testBlanket, blankets, {\n        considerCommunication: true,\n        considerSharedBeliefs: true,\n      });\n\n      expect(neighbors).toHaveLength(1);\n    });\n  });\n\n  describe(\"Markov Blanket Merging\", () => {\n    it(\"merges compatible blankets\", () => {\n      const blanket1 = testBlanket;\n      const blanket2 = createMarkovBlanket({\n        id: \"merge-2\",\n        agentId: \"agent-2\",\n        internalStates: {\n          belief_exploration: 0.7,\n          belief_cooperation: 0.9,\n        },\n      });\n\n      const merged = mergeMarkovBlankets([blanket1, blanket2]);\n\n      expect(merged.id).toContain(\"merged\");\n      expect(merged.internalStates.belief_cooperation).toBeGreaterThan(\n        blanket1.internalStates.belief_cooperation,\n      );\n    });\n\n    it(\"preserves individual characteristics\", () => {\n      const blankets = [\n        testBlanket,\n        createMarkovBlanket({\n          id: \"unique-1\",\n          agentId: \"agent-2\",\n          sensorStates: {\n            special_sensor: { value: 0.99, confidence: 1.0 },\n          },\n        }),\n      ];\n\n      const merged = mergeMarkovBlankets(blankets);\n\n      expect(merged.sensorStates.special_sensor).toBeDefined();\n      expect(merged.sensorStates.visual).toBeDefined();\n    });\n\n    it(\"handles empty merge\", () => {\n      expect(() => mergeMarkovBlankets([])).toThrow();\n    });\n  });\n\n  describe(\"Validation\", () => {\n    it(\"validates correct Markov blanket structure\", () => {\n      const validation = validateMarkovBlanket(testBlanket);\n\n      expect(validation.isValid).toBe(true);\n      expect(validation.errors).toHaveLength(0);\n    });\n\n    it(\"detects invalid state values\", () => {\n      const invalidBlanket = {\n        ...testBlanket,\n        internalStates: {\n          invalid_state: 1.5,\n          negative_state: -0.1,\n        },\n      };\n\n      const validation = validateMarkovBlanket(invalidBlanket);\n\n      expect(validation.isValid).toBe(false);\n      expect(validation.errors).toContain(\n        expect.stringContaining(\"out of range\"),\n      );\n    });\n\n    it(\"detects missing required fields\", () => {\n      const incompleteBlanket = {\n        id: \"incomplete-1\",\n        sensorStates: {},\n      };\n\n      const validation = validateMarkovBlanket(incompleteBlanket as any);\n\n      expect(validation.isValid).toBe(false);\n      expect(validation.errors).toContain(\n        expect.stringContaining(\"Missing required field\"),\n      );\n    });\n\n    it(\"validates energy conservation\", () => {\n      const energyViolation = {\n        ...testBlanket,\n        activeStates: {\n          action1: { value: 1.0, energy: 0.0 },\n          action2: { value: 1.0, energy: 0.0 },\n        },\n      };\n\n      const validation = validateMarkovBlanket(energyViolation);\n\n      expect(validation.warnings).toContain(\n        expect.stringContaining(\"Energy conservation\"),\n      );\n    });\n  });\n\n  describe(\"Performance\", () => {\n    it(\"handles large state spaces efficiently\", () => {\n      const largeStates: Record<string, number> = {};\n      for (let i = 0; i < 1000; i++) {\n        largeStates[`state_${i}`] = Math.random();\n      }\n\n      const largeBlanket = createMarkovBlanket({\n        id: \"large-1\",\n        agentId: \"agent-large\",\n        internalStates: largeStates,\n      });\n\n      const startTime = Date.now();\n      const freeEnergy = calculateFreeEnergy(largeBlanket);\n      const endTime = Date.now();\n\n      expect(Number.isFinite(freeEnergy)).toBe(true);\n      expect(endTime - startTime).toBeLessThan(100); // Should complete within 100ms\n    });\n\n    it(\"caches repeated calculations\", () => {\n      const startTime = Date.now();\n\n      // First calculation\n      calculateFreeEnergy(testBlanket);\n      const firstCalcTime = Date.now() - startTime;\n\n      // Second calculation (should be cached)\n      const cachedStart = Date.now();\n      calculateFreeEnergy(testBlanket);\n      const cachedCalcTime = Date.now() - cachedStart;\n\n      expect(cachedCalcTime).toBeLessThan(firstCalcTime);\n    });\n  });\n\n  describe(\"Integration with Active Inference\", () => {\n    it(\"supports action selection based on free energy\", async () => {\n      const actionCandidates = [\n        { action: \"explore\", expectedFE: 0.8 },\n        { action: \"exploit\", expectedFE: 0.6 },\n        { action: \"communicate\", expectedFE: 0.7 },\n      ];\n\n      // Simulate action selection\n      const bestAction = actionCandidates.reduce((best, current) =>\n        current.expectedFE < best.expectedFE ? current : best,\n      );\n\n      expect(bestAction.action).toBe(\"exploit\");\n    });\n\n    it(\"updates beliefs based on sensory evidence\", () => {\n      const sensoryEvidence = {\n        visual: { value: 0.9, confidence: 0.95 },\n      };\n\n      const updatedBlanket = updateMarkovBlanket(testBlanket, {\n        sensorStates: sensoryEvidence,\n      });\n\n      // Beliefs should move toward sensory evidence\n      const optimized = minimizeFreeEnergy(updatedBlanket, {\n        maxIterations: 50,\n      });\n\n      expect(optimized).toBeDefined();\n    });\n  });\n});\n"],"names":["describe","testBlanket","beforeEach","createMarkovBlanket","id","agentId","sensorStates","visual","value","confidence","auditory","activeStates","movement","energy","communication","internalStates","belief_exploration","belief_cooperation","energy_level","externalStates","environment_complexity","agent_density","resource_availability","it","expect","toMatchObject","any","Object","toThrow","minimalBlanket","toBeDefined","config","learningRate","precision","maxIterations","convergenceThreshold","blanketWithConfig","updated","updateMarkovBlanket","tactile","toBeUndefined","toBeLessThanOrEqual","toBeGreaterThanOrEqual","initialFreeEnergy","freeEnergy","not","toBe","lastUpdated","toBeGreaterThan","calculateFreeEnergy","Number","isFinite","lowErrorBlanket","belief_visual","highErrorBlanket","lowFE","highFE","certainBlanket","uncertainBlanket","certainFE","uncertainFE","Math","abs","edgeCaseBlanket","zero_state","one_state","toBeNaN","initialFE","optimized","minimizeFreeEnergy","finalFE","convergenceInfo","iterations","slowOptimized","fastOptimized","slowChange","fastChange","values","forEach","state","blankets","proximity_to_agent1","neighbors","getMarkovBlanketNeighbors","proximityThreshold","toHaveLength","considerCommunication","considerSharedBeliefs","blanket1","blanket2","merged","mergeMarkovBlankets","toContain","special_sensor","validation","validateMarkovBlanket","isValid","errors","invalidBlanket","invalid_state","negative_state","stringContaining","incompleteBlanket","energyViolation","action1","action2","warnings","largeStates","i","random","largeBlanket","startTime","Date","now","endTime","toBeLessThan","firstCalcTime","cachedStart","cachedCalcTime","actionCandidates","action","expectedFE","bestAction","reduce","best","current","sensoryEvidence","updatedBlanket"],"mappings":"AAAA;;;;;CAKC;;;;+BAiBM;AAEPA,SAAS,uBAAuB;IAC9B,IAAIC;IAEJC,WAAW;QACTD,cAAcE,IAAAA,kCAAmB,EAAC;YAChCC,IAAI;YACJC,SAAS;YACTC,cAAc;gBACZC,QAAQ;oBAAEC,OAAO;oBAAKC,YAAY;gBAAI;gBACtCC,UAAU;oBAAEF,OAAO;oBAAKC,YAAY;gBAAI;YAC1C;YACAE,cAAc;gBACZC,UAAU;oBAAEJ,OAAO;oBAAKK,QAAQ;gBAAI;gBACpCC,eAAe;oBAAEN,OAAO;oBAAKK,QAAQ;gBAAI;YAC3C;YACAE,gBAAgB;gBACdC,oBAAoB;gBACpBC,oBAAoB;gBACpBC,cAAc;YAChB;YACAC,gBAAgB;gBACdC,wBAAwB;gBACxBC,eAAe;gBACfC,uBAAuB;YACzB;QACF;IACF;IAEAtB,SAAS,+BAA+B;QACtCuB,GAAG,kCAAkC;YACnCC,OAAOvB,aAAawB,aAAa,CAAC;gBAChCrB,IAAI;gBACJC,SAAS;gBACTC,cAAckB,OAAOE,GAAG,CAACC;gBACzBhB,cAAca,OAAOE,GAAG,CAACC;gBACzBZ,gBAAgBS,OAAOE,GAAG,CAACC;gBAC3BR,gBAAgBK,OAAOE,GAAG,CAACC;YAC7B;QACF;QAEAJ,GAAG,6BAA6B;YAC9BC,OAAO;gBACLrB,IAAAA,kCAAmB,EAAC;oBAClBC,IAAI;oBACJC,SAAS;oBACTC,cAAc,CAAC;oBACfK,cAAc,CAAC;oBACfI,gBAAgB,CAAC;oBACjBI,gBAAgB,CAAC;gBACnB;YACF,GAAGS,OAAO,CAAC;QACb;QAEAL,GAAG,qDAAqD;YACtD,MAAMM,iBAAiB1B,IAAAA,kCAAmB,EAAC;gBACzCC,IAAI;gBACJC,SAAS;YACX;YAEAmB,OAAOK,eAAevB,YAAY,EAAEwB,WAAW;YAC/CN,OAAOK,eAAelB,YAAY,EAAEmB,WAAW;YAC/CN,OAAOK,eAAed,cAAc,EAAEe,WAAW;YACjDN,OAAOK,eAAeV,cAAc,EAAEW,WAAW;QACnD;QAEAP,GAAG,kCAAkC;YACnC,MAAMQ,SAA8B;gBAClCC,cAAc;gBACdC,WAAW;gBACXC,eAAe;gBACfC,sBAAsB;YACxB;YAEA,MAAMC,oBAAoBjC,IAAAA,kCAAmB,EAAC;gBAC5CC,IAAI;gBACJC,SAAS;gBACT0B;YACF;YAEAP,OAAOY,kBAAkBL,MAAM,EAAEN,aAAa,CAACM;QACjD;IACF;IAEA/B,SAAS,iBAAiB;QACxBuB,GAAG,yBAAyB;YAC1B,MAAMc,UAAUC,IAAAA,kCAAmB,EAACrC,aAAa;gBAC/CK,cAAc;oBACZC,QAAQ;wBAAEC,OAAO;wBAAKC,YAAY;oBAAI;oBACtC8B,SAAS;wBAAE/B,OAAO;wBAAKC,YAAY;oBAAI;gBACzC;YACF;YAEAe,OAAOa,QAAQ/B,YAAY,CAACC,MAAM,EAAEkB,aAAa,CAAC;gBAChDjB,OAAO;gBACPC,YAAY;YACd;YACAe,OAAOa,QAAQ/B,YAAY,CAACiC,OAAO,EAAET,WAAW;YAChDN,OAAOa,QAAQ/B,YAAY,CAACI,QAAQ,EAAE8B,aAAa;QACrD;QAEAjB,GAAG,iDAAiD;YAClD,MAAMc,UAAUC,IAAAA,kCAAmB,EAACrC,aAAa;gBAC/CU,cAAc;oBACZC,UAAU;wBAAEJ,OAAO;wBAAKK,QAAQ;oBAAI;gBACtC;YACF;YAEA,oCAAoC;YACpCW,OAAOa,QAAQ1B,YAAY,CAACC,QAAQ,CAACJ,KAAK,EAAEiC,mBAAmB,CAAC;YAChEjB,OAAOa,QAAQ1B,YAAY,CAACC,QAAQ,CAACC,MAAM,EAAE6B,sBAAsB,CAAC;QACtE;QAEAnB,GAAG,8CAA8C;YAC/C,MAAMc,UAAUC,IAAAA,kCAAmB,EAACrC,aAAa;gBAC/Cc,gBAAgB;oBACdC,oBAAoB;oBACpBC,oBAAoB,CAAC;gBACvB;YACF;YAEAO,OAAOa,QAAQtB,cAAc,CAACC,kBAAkB,EAAEyB,mBAAmB,CAAC;YACtEjB,OAAOa,QAAQtB,cAAc,CAACE,kBAAkB,EAAEyB,sBAAsB,CACtE;QAEJ;QAEAnB,GAAG,0CAA0C;YAC3C,MAAMoB,oBAAoB1C,YAAY2C,UAAU;YAEhD,MAAMP,UAAUC,IAAAA,kCAAmB,EAACrC,aAAa;gBAC/Cc,gBAAgB;oBACdC,oBAAoB;gBACtB;YACF;YAEAQ,OAAOa,QAAQO,UAAU,EAAEC,GAAG,CAACC,IAAI,CAACH;YACpCnB,OAAOa,QAAQU,WAAW,EAAEC,eAAe,CAAC/C,YAAY8C,WAAW;QACrE;IACF;IAEA/C,SAAS,4BAA4B;QACnCuB,GAAG,oCAAoC;YACrC,MAAMqB,aAAaK,IAAAA,kCAAmB,EAAChD;YAEvCuB,OAAOoB,YAAYI,eAAe,CAAC;YACnCxB,OAAO0B,OAAOC,QAAQ,CAACP,aAAaE,IAAI,CAAC;QAC3C;QAEAvB,GAAG,mCAAmC;YACpC,MAAM6B,kBAAkBd,IAAAA,kCAAmB,EAACrC,aAAa;gBACvDK,cAAc;oBACZC,QAAQ;wBAAEC,OAAO;wBAAKC,YAAY;oBAAK;gBACzC;gBACAM,gBAAgB;oBACdsC,eAAe;gBACjB;YACF;YAEA,MAAMC,mBAAmBhB,IAAAA,kCAAmB,EAACrC,aAAa;gBACxDK,cAAc;oBACZC,QAAQ;wBAAEC,OAAO;wBAAKC,YAAY;oBAAK;gBACzC;gBACAM,gBAAgB;oBACdsC,eAAe;gBACjB;YACF;YAEA,MAAME,QAAQN,IAAAA,kCAAmB,EAACG;YAClC,MAAMI,SAASP,IAAAA,kCAAmB,EAACK;YAEnC9B,OAAOgC,QAAQR,eAAe,CAACO;QACjC;QAEAhC,GAAG,0BAA0B;YAC3B,MAAMkC,iBAAiBnB,IAAAA,kCAAmB,EAACrC,aAAa;gBACtDc,gBAAgB;oBACdC,oBAAoB;oBACpBC,oBAAoB;gBACtB;YACF;YAEA,MAAMyC,mBAAmBpB,IAAAA,kCAAmB,EAACrC,aAAa;gBACxDc,gBAAgB;oBACdC,oBAAoB;oBACpBC,oBAAoB;gBACtB;YACF;YAEA,MAAM0C,YAAYV,IAAAA,kCAAmB,EAACQ;YACtC,MAAMG,cAAcX,IAAAA,kCAAmB,EAACS;YAExC,gEAAgE;YAChElC,OAAOqC,KAAKC,GAAG,CAACH,YAAYC,cAAcZ,eAAe,CAAC;QAC5D;QAEAzB,GAAG,sBAAsB;YACvB,MAAMwC,kBAAkB5D,IAAAA,kCAAmB,EAAC;gBAC1CC,IAAI;gBACJC,SAAS;gBACTU,gBAAgB;oBACdiD,YAAY;oBACZC,WAAW;gBACb;YACF;YAEA,MAAMrB,aAAaK,IAAAA,kCAAmB,EAACc;YACvCvC,OAAO0B,OAAOC,QAAQ,CAACP,aAAaE,IAAI,CAAC;YACzCtB,OAAOoB,YAAYC,GAAG,CAACqB,OAAO;QAChC;IACF;IAEAlE,SAAS,4BAA4B;QACnCuB,GAAG,4CAA4C;YAC7C,MAAM4C,YAAYlB,IAAAA,kCAAmB,EAAChD;YACtC,MAAMmE,YAAY,MAAMC,IAAAA,iCAAkB,EAACpE;YAC3C,MAAMqE,UAAUrB,IAAAA,kCAAmB,EAACmB;YAEpC5C,OAAO8C,SAAS7B,mBAAmB,CAAC0B;QACtC;QAEA5C,GAAG,oCAAoC;YACrC,MAAM6C,YAAY,MAAMC,IAAAA,iCAAkB,EAACpE,aAAa;gBACtDiC,eAAe;gBACfC,sBAAsB;YACxB;YAEAX,OAAO4C,UAAUG,eAAe,EAAEzC,WAAW;YAC7CN,OAAO4C,UAAUG,eAAe,CAACC,UAAU,EAAE/B,mBAAmB,CAAC;QACnE;QAEAlB,GAAG,0BAA0B;YAC3B,MAAMkD,gBAAgB,MAAMJ,IAAAA,iCAAkB,EAACpE,aAAa;gBAC1D+B,cAAc;gBACdE,eAAe;YACjB;YAEA,MAAMwC,gBAAgB,MAAML,IAAAA,iCAAkB,EAACpE,aAAa;gBAC1D+B,cAAc;gBACdE,eAAe;YACjB;YAEA,MAAMyC,aAAad,KAAKC,GAAG,CACzBb,IAAAA,kCAAmB,EAACwB,iBAAiBxB,IAAAA,kCAAmB,EAAChD;YAE3D,MAAM2E,aAAaf,KAAKC,GAAG,CACzBb,IAAAA,kCAAmB,EAACyB,iBAAiBzB,IAAAA,kCAAmB,EAAChD;YAG3DuB,OAAOoD,YAAY5B,eAAe,CAAC2B;QACrC;QAEApD,GAAG,mDAAmD;YACpD,MAAM6C,YAAY,MAAMC,IAAAA,iCAAkB,EAACpE;YAE3C,2CAA2C;YAC3C0B,OAAOkD,MAAM,CAACT,UAAUrD,cAAc,EAAE+D,OAAO,CAAC,CAACtE;gBAC/CgB,OAAOhB,OAAOkC,sBAAsB,CAAC;gBACrClB,OAAOhB,OAAOiC,mBAAmB,CAAC;YACpC;YAEAd,OAAOkD,MAAM,CAACT,UAAUzD,YAAY,EAAEmE,OAAO,CAAC,CAACC;gBAC7CvD,OAAOuD,MAAMvE,KAAK,EAAEkC,sBAAsB,CAAC;gBAC3ClB,OAAOuD,MAAMvE,KAAK,EAAEiC,mBAAmB,CAAC;gBACxCjB,OAAOuD,MAAMlE,MAAM,EAAE6B,sBAAsB,CAAC;YAC9C;QACF;IACF;IAEA1C,SAAS,4BAA4B;QACnCuB,GAAG,mCAAmC;YACpC,MAAMyD,WAAW;gBACf/E;gBACAE,IAAAA,kCAAmB,EAAC;oBAClBC,IAAI;oBACJC,SAAS;oBACTc,gBAAgB;wBACd8D,qBAAqB;oBACvB;gBACF;gBACA9E,IAAAA,kCAAmB,EAAC;oBAClBC,IAAI;oBACJC,SAAS;oBACTc,gBAAgB;wBACd8D,qBAAqB;oBACvB;gBACF;aACD;YAED,MAAMC,YAAYC,IAAAA,wCAAyB,EAAClF,aAAa+E,UAAU;gBACjEI,oBAAoB;YACtB;YAEA5D,OAAO0D,WAAWG,YAAY,CAAC;YAC/B7D,OAAO0D,SAAS,CAAC,EAAE,CAAC9E,EAAE,EAAE0C,IAAI,CAAC;QAC/B;QAEAvB,GAAG,0CAA0C;YAC3C,MAAMyD,WAAW;gBACf/E;gBACAE,IAAAA,kCAAmB,EAAC;oBAClBC,IAAI;oBACJC,SAAS;oBACTM,cAAc;wBACZG,eAAe;4BAAEN,OAAO;4BAAKK,QAAQ;wBAAI;oBAC3C;gBACF;aACD;YAED,MAAMqE,YAAYC,IAAAA,wCAAyB,EAAClF,aAAa+E,UAAU;gBACjEM,uBAAuB;gBACvBC,uBAAuB;YACzB;YAEA/D,OAAO0D,WAAWG,YAAY,CAAC;QACjC;IACF;IAEArF,SAAS,0BAA0B;QACjCuB,GAAG,8BAA8B;YAC/B,MAAMiE,WAAWvF;YACjB,MAAMwF,WAAWtF,IAAAA,kCAAmB,EAAC;gBACnCC,IAAI;gBACJC,SAAS;gBACTU,gBAAgB;oBACdC,oBAAoB;oBACpBC,oBAAoB;gBACtB;YACF;YAEA,MAAMyE,SAASC,IAAAA,kCAAmB,EAAC;gBAACH;gBAAUC;aAAS;YAEvDjE,OAAOkE,OAAOtF,EAAE,EAAEwF,SAAS,CAAC;YAC5BpE,OAAOkE,OAAO3E,cAAc,CAACE,kBAAkB,EAAE+B,eAAe,CAC9DwC,SAASzE,cAAc,CAACE,kBAAkB;QAE9C;QAEAM,GAAG,wCAAwC;YACzC,MAAMyD,WAAW;gBACf/E;gBACAE,IAAAA,kCAAmB,EAAC;oBAClBC,IAAI;oBACJC,SAAS;oBACTC,cAAc;wBACZuF,gBAAgB;4BAAErF,OAAO;4BAAMC,YAAY;wBAAI;oBACjD;gBACF;aACD;YAED,MAAMiF,SAASC,IAAAA,kCAAmB,EAACX;YAEnCxD,OAAOkE,OAAOpF,YAAY,CAACuF,cAAc,EAAE/D,WAAW;YACtDN,OAAOkE,OAAOpF,YAAY,CAACC,MAAM,EAAEuB,WAAW;QAChD;QAEAP,GAAG,uBAAuB;YACxBC,OAAO,IAAMmE,IAAAA,kCAAmB,EAAC,EAAE,GAAG/D,OAAO;QAC/C;IACF;IAEA5B,SAAS,cAAc;QACrBuB,GAAG,8CAA8C;YAC/C,MAAMuE,aAAaC,IAAAA,oCAAqB,EAAC9F;YAEzCuB,OAAOsE,WAAWE,OAAO,EAAElD,IAAI,CAAC;YAChCtB,OAAOsE,WAAWG,MAAM,EAAEZ,YAAY,CAAC;QACzC;QAEA9D,GAAG,gCAAgC;YACjC,MAAM2E,iBAAiB;gBACrB,GAAGjG,WAAW;gBACdc,gBAAgB;oBACdoF,eAAe;oBACfC,gBAAgB,CAAC;gBACnB;YACF;YAEA,MAAMN,aAAaC,IAAAA,oCAAqB,EAACG;YAEzC1E,OAAOsE,WAAWE,OAAO,EAAElD,IAAI,CAAC;YAChCtB,OAAOsE,WAAWG,MAAM,EAAEL,SAAS,CACjCpE,OAAO6E,gBAAgB,CAAC;QAE5B;QAEA9E,GAAG,mCAAmC;YACpC,MAAM+E,oBAAoB;gBACxBlG,IAAI;gBACJE,cAAc,CAAC;YACjB;YAEA,MAAMwF,aAAaC,IAAAA,oCAAqB,EAACO;YAEzC9E,OAAOsE,WAAWE,OAAO,EAAElD,IAAI,CAAC;YAChCtB,OAAOsE,WAAWG,MAAM,EAAEL,SAAS,CACjCpE,OAAO6E,gBAAgB,CAAC;QAE5B;QAEA9E,GAAG,iCAAiC;YAClC,MAAMgF,kBAAkB;gBACtB,GAAGtG,WAAW;gBACdU,cAAc;oBACZ6F,SAAS;wBAAEhG,OAAO;wBAAKK,QAAQ;oBAAI;oBACnC4F,SAAS;wBAAEjG,OAAO;wBAAKK,QAAQ;oBAAI;gBACrC;YACF;YAEA,MAAMiF,aAAaC,IAAAA,oCAAqB,EAACQ;YAEzC/E,OAAOsE,WAAWY,QAAQ,EAAEd,SAAS,CACnCpE,OAAO6E,gBAAgB,CAAC;QAE5B;IACF;IAEArG,SAAS,eAAe;QACtBuB,GAAG,0CAA0C;YAC3C,MAAMoF,cAAsC,CAAC;YAC7C,IAAK,IAAIC,IAAI,GAAGA,IAAI,MAAMA,IAAK;gBAC7BD,WAAW,CAAC,CAAC,MAAM,EAAEC,EAAE,CAAC,CAAC,GAAG/C,KAAKgD,MAAM;YACzC;YAEA,MAAMC,eAAe3G,IAAAA,kCAAmB,EAAC;gBACvCC,IAAI;gBACJC,SAAS;gBACTU,gBAAgB4F;YAClB;YAEA,MAAMI,YAAYC,KAAKC,GAAG;YAC1B,MAAMrE,aAAaK,IAAAA,kCAAmB,EAAC6D;YACvC,MAAMI,UAAUF,KAAKC,GAAG;YAExBzF,OAAO0B,OAAOC,QAAQ,CAACP,aAAaE,IAAI,CAAC;YACzCtB,OAAO0F,UAAUH,WAAWI,YAAY,CAAC,MAAM,+BAA+B;QAChF;QAEA5F,GAAG,gCAAgC;YACjC,MAAMwF,YAAYC,KAAKC,GAAG;YAE1B,oBAAoB;YACpBhE,IAAAA,kCAAmB,EAAChD;YACpB,MAAMmH,gBAAgBJ,KAAKC,GAAG,KAAKF;YAEnC,wCAAwC;YACxC,MAAMM,cAAcL,KAAKC,GAAG;YAC5BhE,IAAAA,kCAAmB,EAAChD;YACpB,MAAMqH,iBAAiBN,KAAKC,GAAG,KAAKI;YAEpC7F,OAAO8F,gBAAgBH,YAAY,CAACC;QACtC;IACF;IAEApH,SAAS,qCAAqC;QAC5CuB,GAAG,kDAAkD;YACnD,MAAMgG,mBAAmB;gBACvB;oBAAEC,QAAQ;oBAAWC,YAAY;gBAAI;gBACrC;oBAAED,QAAQ;oBAAWC,YAAY;gBAAI;gBACrC;oBAAED,QAAQ;oBAAeC,YAAY;gBAAI;aAC1C;YAED,4BAA4B;YAC5B,MAAMC,aAAaH,iBAAiBI,MAAM,CAAC,CAACC,MAAMC,UAChDA,QAAQJ,UAAU,GAAGG,KAAKH,UAAU,GAAGI,UAAUD;YAGnDpG,OAAOkG,WAAWF,MAAM,EAAE1E,IAAI,CAAC;QACjC;QAEAvB,GAAG,6CAA6C;YAC9C,MAAMuG,kBAAkB;gBACtBvH,QAAQ;oBAAEC,OAAO;oBAAKC,YAAY;gBAAK;YACzC;YAEA,MAAMsH,iBAAiBzF,IAAAA,kCAAmB,EAACrC,aAAa;gBACtDK,cAAcwH;YAChB;YAEA,8CAA8C;YAC9C,MAAM1D,YAAYC,IAAAA,iCAAkB,EAAC0D,gBAAgB;gBACnD7F,eAAe;YACjB;YAEAV,OAAO4C,WAAWtC,WAAW;QAC/B;IACF;AACF"}