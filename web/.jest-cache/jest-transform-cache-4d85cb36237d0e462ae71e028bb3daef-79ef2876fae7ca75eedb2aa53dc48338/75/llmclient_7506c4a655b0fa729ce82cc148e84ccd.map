{"version":3,"sources":["/Users/matthewmoroney/builds/FreeAgentics/web/lib/llm-client.ts"],"sourcesContent":["export interface LLMClientConfig {\n  provider: string;\n  apiKey: string;\n  useSecureStorage?: boolean;\n  providers?: Array<{ provider: string; priority: number }>;\n  enableCache?: boolean;\n  cacheTimeout?: number;\n}\n\nexport class LLMClient {\n  provider: string;\n  private apiKey: string;\n  providers?: Array<{ provider: string; priority: number }>;\n\n  constructor(config: LLMClientConfig) {\n    const validProviders = [\"openai\", \"anthropic\", \"google\", \"azure\"];\n    if (!validProviders.includes(config.provider)) {\n      throw new Error(\"Invalid provider\");\n    }\n\n    this.provider = config.provider;\n    this.apiKey = config.apiKey;\n    this.providers = config.providers;\n\n    if (config.useSecureStorage) {\n      const { encrypt } = require(\"@/lib/encryption\");\n      encrypt(config.apiKey);\n    }\n  }\n\n  async chat(messages: any[]): Promise<any> {\n    const response = await fetch(`/api/llm/${this.provider}/chat/completions`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Authorization: `Bearer ${this.apiKey}`,\n      },\n      body: JSON.stringify({ messages }),\n    });\n\n    if (!response.ok) {\n      if (response.status === 429) {\n        const { RateLimitError } = await import(\"@/lib/llm-errors\");\n        throw new RateLimitError(\"Rate limit exceeded\");\n      }\n      if (response.status === 401) {\n        const { AuthenticationError } = await import(\"@/lib/llm-errors\");\n        throw new AuthenticationError(\"Invalid API key\");\n      }\n      throw new Error(\"Request failed\");\n    }\n\n    return response.json();\n  }\n\n  async chatStream(messages: any[]): Promise<ReadableStream> {\n    const response = await fetch(`/api/llm/${this.provider}/chat/completions`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Authorization: `Bearer ${this.apiKey}`,\n      },\n      body: JSON.stringify({ messages, stream: true }),\n    });\n\n    if (!response.body) {\n      throw new Error(\"No response body\");\n    }\n\n    return response.body;\n  }\n\n  getProvidersByPriority(): Array<{ provider: string; priority: number }> {\n    return this.providers || [];\n  }\n\n  async setProvider(provider: string): Promise<void> {\n    this.provider = provider;\n  }\n\n  countTokens(text: string): number {\n    // Simple approximation\n    return Math.ceil(text.split(/\\s+/).length * 1.3);\n  }\n\n  clearCache(): void {\n    // Clear any cached responses\n  }\n\n  addRequestInterceptor(interceptor: Function): void {\n    // Add request interceptor\n  }\n\n  addResponseInterceptor(interceptor: Function): void {\n    // Add response interceptor\n  }\n\n  async createEmbedding(text: string): Promise<number[]> {\n    const response = await fetch(`/api/llm/${this.provider}/embeddings`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Authorization: `Bearer ${this.apiKey}`,\n      },\n      body: JSON.stringify({ input: text }),\n    });\n\n    const data = await response.json();\n    return data.embedding;\n  }\n\n  async analyzeImage(imageUrl: string, prompt: string): Promise<string> {\n    const response = await fetch(`/api/llm/${this.provider}/vision`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        Authorization: `Bearer ${this.apiKey}`,\n      },\n      body: JSON.stringify({ image_url: imageUrl, prompt }),\n    });\n\n    const data = await response.json();\n    return data.description;\n  }\n\n  async getFineTuneStatus(modelId: string): Promise<any> {\n    const response = await fetch(\n      `/api/llm/${this.provider}/fine-tunes/${modelId}`,\n      {\n        headers: {\n          Authorization: `Bearer ${this.apiKey}`,\n        },\n      },\n    );\n\n    return response.json();\n  }\n\n  // Settings management methods\n  getSettings(): any {\n    return {\n      provider: this.provider,\n      apiKey: this.apiKey ? \"***\" : \"\", // Hide actual key\n      providers: this.providers,\n    };\n  }\n\n  updateSettings(settings: any): void {\n    if (settings.provider) this.provider = settings.provider;\n    if (settings.apiKey) this.apiKey = settings.apiKey;\n    if (settings.providers) this.providers = settings.providers;\n  }\n\n  async saveSettings(): Promise<boolean> {\n    // Save settings to storage/preferences\n    return Promise.resolve(true);\n  }\n\n  // Response generation methods\n  async generateResponse(prompt: string, options?: any): Promise<string> {\n    const messages = [{ role: \"user\", content: prompt }];\n    const response = await this.chat(messages);\n    return response.choices?.[0]?.message?.content || \"\";\n  }\n\n  async streamResponse(\n    prompt: string,\n    userPrompt?: string,\n    onChunk?: Function,\n  ): Promise<string> {\n    // For compatibility, if streaming is requested, we'll still return a string\n    // but call the onChunk callback if provided\n    const messages = [{ role: \"user\", content: prompt }];\n    if (userPrompt) {\n      messages.push({ role: \"user\", content: userPrompt });\n    }\n\n    const response = await this.chat(messages);\n    const content = response.choices?.[0]?.message?.content || \"\";\n\n    // Call onChunk if provided (for compatibility)\n    if (onChunk) {\n      onChunk({ text: content, isComplete: true });\n    }\n\n    return content;\n  }\n\n  // Belief extraction method\n  async extractBeliefs(content: string): Promise<any> {\n    const prompt = `Extract beliefs and convictions from the following content: ${content}`;\n    const response = await this.generateResponse(prompt);\n    try {\n      return JSON.parse(response);\n    } catch {\n      return { beliefs: [], raw: response };\n    }\n  }\n\n  // Token usage tracking\n  getTokenUsage(): any {\n    return {\n      totalTokens: 0,\n      promptTokens: 0,\n      completionTokens: 0,\n    };\n  }\n\n  // Performance metrics\n  getPerformanceMetrics(): any {\n    return {\n      averageResponseTime: 0,\n      successRate: 1.0,\n      errorRate: 0.0,\n    };\n  }\n}\n\n// Export a default instance\nexport const llmClient = new LLMClient({\n  provider: \"openai\",\n  apiKey: process.env.OPENAI_API_KEY || \"dummy-key\",\n});\n"],"names":["LLMClient","llmClient","constructor","config","validProviders","includes","provider","Error","apiKey","providers","useSecureStorage","encrypt","require","chat","messages","response","fetch","method","headers","Authorization","body","JSON","stringify","ok","status","RateLimitError","AuthenticationError","json","chatStream","stream","getProvidersByPriority","setProvider","countTokens","text","Math","ceil","split","length","clearCache","addRequestInterceptor","interceptor","addResponseInterceptor","createEmbedding","input","data","embedding","analyzeImage","imageUrl","prompt","image_url","description","getFineTuneStatus","modelId","getSettings","updateSettings","settings","saveSettings","Promise","resolve","generateResponse","options","role","content","choices","message","streamResponse","userPrompt","onChunk","push","isComplete","extractBeliefs","parse","beliefs","raw","getTokenUsage","totalTokens","promptTokens","completionTokens","getPerformanceMetrics","averageResponseTime","successRate","errorRate","process","env","OPENAI_API_KEY"],"mappings":";;;;;;;;;;;IASaA,SAAS;eAATA;;IAkNAC,SAAS;eAATA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAlNN,MAAMD;IAKXE,YAAYC,MAAuB,CAAE;QACnC,MAAMC,iBAAiB;YAAC;YAAU;YAAa;YAAU;SAAQ;QACjE,IAAI,CAACA,eAAeC,QAAQ,CAACF,OAAOG,QAAQ,GAAG;YAC7C,MAAM,IAAIC,MAAM;QAClB;QAEA,IAAI,CAACD,QAAQ,GAAGH,OAAOG,QAAQ;QAC/B,IAAI,CAACE,MAAM,GAAGL,OAAOK,MAAM;QAC3B,IAAI,CAACC,SAAS,GAAGN,OAAOM,SAAS;QAEjC,IAAIN,OAAOO,gBAAgB,EAAE;YAC3B,MAAM,EAAEC,OAAO,EAAE,GAAGC,QAAQ;YAC5BD,QAAQR,OAAOK,MAAM;QACvB;IACF;IAEA,MAAMK,KAAKC,QAAe,EAAgB;QACxC,MAAMC,WAAW,MAAMC,MAAM,CAAC,SAAS,EAAE,IAAI,CAACV,QAAQ,CAAC,iBAAiB,CAAC,EAAE;YACzEW,QAAQ;YACRC,SAAS;gBACP,gBAAgB;gBAChBC,eAAe,CAAC,OAAO,EAAE,IAAI,CAACX,MAAM,CAAC,CAAC;YACxC;YACAY,MAAMC,KAAKC,SAAS,CAAC;gBAAER;YAAS;QAClC;QAEA,IAAI,CAACC,SAASQ,EAAE,EAAE;YAChB,IAAIR,SAASS,MAAM,KAAK,KAAK;gBAC3B,MAAM,EAAEC,cAAc,EAAE,GAAG,MAAM,mEAAA,QAAO;gBACxC,MAAM,IAAIA,eAAe;YAC3B;YACA,IAAIV,SAASS,MAAM,KAAK,KAAK;gBAC3B,MAAM,EAAEE,mBAAmB,EAAE,GAAG,MAAM,mEAAA,QAAO;gBAC7C,MAAM,IAAIA,oBAAoB;YAChC;YACA,MAAM,IAAInB,MAAM;QAClB;QAEA,OAAOQ,SAASY,IAAI;IACtB;IAEA,MAAMC,WAAWd,QAAe,EAA2B;QACzD,MAAMC,WAAW,MAAMC,MAAM,CAAC,SAAS,EAAE,IAAI,CAACV,QAAQ,CAAC,iBAAiB,CAAC,EAAE;YACzEW,QAAQ;YACRC,SAAS;gBACP,gBAAgB;gBAChBC,eAAe,CAAC,OAAO,EAAE,IAAI,CAACX,MAAM,CAAC,CAAC;YACxC;YACAY,MAAMC,KAAKC,SAAS,CAAC;gBAAER;gBAAUe,QAAQ;YAAK;QAChD;QAEA,IAAI,CAACd,SAASK,IAAI,EAAE;YAClB,MAAM,IAAIb,MAAM;QAClB;QAEA,OAAOQ,SAASK,IAAI;IACtB;IAEAU,yBAAwE;QACtE,OAAO,IAAI,CAACrB,SAAS,IAAI,EAAE;IAC7B;IAEA,MAAMsB,YAAYzB,QAAgB,EAAiB;QACjD,IAAI,CAACA,QAAQ,GAAGA;IAClB;IAEA0B,YAAYC,IAAY,EAAU;QAChC,uBAAuB;QACvB,OAAOC,KAAKC,IAAI,CAACF,KAAKG,KAAK,CAAC,OAAOC,MAAM,GAAG;IAC9C;IAEAC,aAAmB;IACjB,6BAA6B;IAC/B;IAEAC,sBAAsBC,WAAqB,EAAQ;IACjD,0BAA0B;IAC5B;IAEAC,uBAAuBD,WAAqB,EAAQ;IAClD,2BAA2B;IAC7B;IAEA,MAAME,gBAAgBT,IAAY,EAAqB;QACrD,MAAMlB,WAAW,MAAMC,MAAM,CAAC,SAAS,EAAE,IAAI,CAACV,QAAQ,CAAC,WAAW,CAAC,EAAE;YACnEW,QAAQ;YACRC,SAAS;gBACP,gBAAgB;gBAChBC,eAAe,CAAC,OAAO,EAAE,IAAI,CAACX,MAAM,CAAC,CAAC;YACxC;YACAY,MAAMC,KAAKC,SAAS,CAAC;gBAAEqB,OAAOV;YAAK;QACrC;QAEA,MAAMW,OAAO,MAAM7B,SAASY,IAAI;QAChC,OAAOiB,KAAKC,SAAS;IACvB;IAEA,MAAMC,aAAaC,QAAgB,EAAEC,MAAc,EAAmB;QACpE,MAAMjC,WAAW,MAAMC,MAAM,CAAC,SAAS,EAAE,IAAI,CAACV,QAAQ,CAAC,OAAO,CAAC,EAAE;YAC/DW,QAAQ;YACRC,SAAS;gBACP,gBAAgB;gBAChBC,eAAe,CAAC,OAAO,EAAE,IAAI,CAACX,MAAM,CAAC,CAAC;YACxC;YACAY,MAAMC,KAAKC,SAAS,CAAC;gBAAE2B,WAAWF;gBAAUC;YAAO;QACrD;QAEA,MAAMJ,OAAO,MAAM7B,SAASY,IAAI;QAChC,OAAOiB,KAAKM,WAAW;IACzB;IAEA,MAAMC,kBAAkBC,OAAe,EAAgB;QACrD,MAAMrC,WAAW,MAAMC,MACrB,CAAC,SAAS,EAAE,IAAI,CAACV,QAAQ,CAAC,YAAY,EAAE8C,QAAQ,CAAC,EACjD;YACElC,SAAS;gBACPC,eAAe,CAAC,OAAO,EAAE,IAAI,CAACX,MAAM,CAAC,CAAC;YACxC;QACF;QAGF,OAAOO,SAASY,IAAI;IACtB;IAEA,8BAA8B;IAC9B0B,cAAmB;QACjB,OAAO;YACL/C,UAAU,IAAI,CAACA,QAAQ;YACvBE,QAAQ,IAAI,CAACA,MAAM,GAAG,QAAQ;YAC9BC,WAAW,IAAI,CAACA,SAAS;QAC3B;IACF;IAEA6C,eAAeC,QAAa,EAAQ;QAClC,IAAIA,SAASjD,QAAQ,EAAE,IAAI,CAACA,QAAQ,GAAGiD,SAASjD,QAAQ;QACxD,IAAIiD,SAAS/C,MAAM,EAAE,IAAI,CAACA,MAAM,GAAG+C,SAAS/C,MAAM;QAClD,IAAI+C,SAAS9C,SAAS,EAAE,IAAI,CAACA,SAAS,GAAG8C,SAAS9C,SAAS;IAC7D;IAEA,MAAM+C,eAAiC;QACrC,uCAAuC;QACvC,OAAOC,QAAQC,OAAO,CAAC;IACzB;IAEA,8BAA8B;IAC9B,MAAMC,iBAAiBX,MAAc,EAAEY,OAAa,EAAmB;QACrE,MAAM9C,WAAW;YAAC;gBAAE+C,MAAM;gBAAQC,SAASd;YAAO;SAAE;QACpD,MAAMjC,WAAW,MAAM,IAAI,CAACF,IAAI,CAACC;QACjC,OAAOC,SAASgD,OAAO,EAAE,CAAC,EAAE,EAAEC,SAASF,WAAW;IACpD;IAEA,MAAMG,eACJjB,MAAc,EACdkB,UAAmB,EACnBC,OAAkB,EACD;QACjB,4EAA4E;QAC5E,4CAA4C;QAC5C,MAAMrD,WAAW;YAAC;gBAAE+C,MAAM;gBAAQC,SAASd;YAAO;SAAE;QACpD,IAAIkB,YAAY;YACdpD,SAASsD,IAAI,CAAC;gBAAEP,MAAM;gBAAQC,SAASI;YAAW;QACpD;QAEA,MAAMnD,WAAW,MAAM,IAAI,CAACF,IAAI,CAACC;QACjC,MAAMgD,UAAU/C,SAASgD,OAAO,EAAE,CAAC,EAAE,EAAEC,SAASF,WAAW;QAE3D,+CAA+C;QAC/C,IAAIK,SAAS;YACXA,QAAQ;gBAAElC,MAAM6B;gBAASO,YAAY;YAAK;QAC5C;QAEA,OAAOP;IACT;IAEA,2BAA2B;IAC3B,MAAMQ,eAAeR,OAAe,EAAgB;QAClD,MAAMd,SAAS,CAAC,4DAA4D,EAAEc,QAAQ,CAAC;QACvF,MAAM/C,WAAW,MAAM,IAAI,CAAC4C,gBAAgB,CAACX;QAC7C,IAAI;YACF,OAAO3B,KAAKkD,KAAK,CAACxD;QACpB,EAAE,OAAM;YACN,OAAO;gBAAEyD,SAAS,EAAE;gBAAEC,KAAK1D;YAAS;QACtC;IACF;IAEA,uBAAuB;IACvB2D,gBAAqB;QACnB,OAAO;YACLC,aAAa;YACbC,cAAc;YACdC,kBAAkB;QACpB;IACF;IAEA,sBAAsB;IACtBC,wBAA6B;QAC3B,OAAO;YACLC,qBAAqB;YACrBC,aAAa;YACbC,WAAW;QACb;IACF;AACF;AAGO,MAAMhF,YAAY,IAAID,UAAU;IACrCM,UAAU;IACVE,QAAQ0E,QAAQC,GAAG,CAACC,cAAc,IAAI;AACxC"}