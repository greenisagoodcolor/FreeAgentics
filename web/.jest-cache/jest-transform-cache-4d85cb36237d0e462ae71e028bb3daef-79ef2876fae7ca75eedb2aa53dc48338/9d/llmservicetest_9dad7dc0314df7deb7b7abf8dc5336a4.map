{"version":3,"sources":["/Users/matthewmoroney/builds/FreeAgentics/web/__tests__/lib/llm-service.test.ts"],"sourcesContent":["/**\n * Phase 1: lib/llm-service.ts Comprehensive Test Suite\n * Target: Complete LLM service orchestration functionality\n * Goal: Maximum statement coverage for core LLM service\n */\n\nimport { jest } from \"@jest/globals\";\nimport type { Mock } from \"jest-mock\";\n\n// Mock modules before importing the module under test\njest.mock(\"@ai-sdk/openai\", () => ({\n  openai: jest.fn((model: string) => ({\n    modelId: model,\n    provider: \"openai\",\n  })),\n  createOpenAI: jest.fn((config: any) => {\n    return (model: string) => ({\n      modelId: model,\n      provider: \"openai\",\n      apiKey: config.apiKey,\n    });\n  }),\n}));\n\njest.mock(\"ai\", () => ({\n  streamText: jest.fn(),\n  generateText: jest.fn(),\n}));\n\njest.mock(\"next/navigation\", () => ({\n  notFound: jest.fn(),\n}));\n\njest.mock(\"@/lib/debug-logger\", () => ({\n  createLogger: jest.fn(() => ({\n    info: jest.fn(),\n    error: jest.fn(),\n    warn: jest.fn(),\n    debug: jest.fn(),\n  })),\n  debugLog: jest.fn(),\n}));\n\njest.mock(\"@/lib/llm-errors\", () => {\n  const originalModule = jest.requireActual(\"@/lib/llm-errors\");\n  return {\n    ...originalModule,\n    withTimeout: jest.fn((promise, timeout, message) => promise),\n  };\n});\n\njest.mock(\"@/lib/utils\", () => ({\n  extractTagsFromMarkdown: jest.fn((text: string) => {\n    const matches = text.match(/\\[\\[([^\\]]+)\\]\\]/g);\n    return matches ? matches.map((m) => m.slice(2, -2)) : [];\n  }),\n}));\n\njest.mock(\"@/lib/llm-settings\", () => ({\n  defaultSettings: {\n    provider: \"openai\",\n    model: \"gpt-4\",\n    apiKey: \"\",\n    temperature: 0.7,\n    maxTokens: 2000,\n    topP: 1,\n    frequencyPenalty: 0,\n    presencePenalty: 0,\n  },\n}));\n\n// Now import the module under test\nimport {\n  generateResponse,\n  streamGenerateResponse,\n  validateResponse,\n  extractBeliefs,\n  generateKnowledgeEntries,\n  validateApiKey,\n  saveLLMSettings,\n  withRetry,\n  type StreamChunk,\n} from \"../../lib/llm-service\";\n\nimport { streamText, generateText } from \"ai\";\nimport { createOpenAI } from \"@ai-sdk/openai\";\nimport { withTimeout } from \"@/lib/llm-errors\";\nimport { extractTagsFromMarkdown } from \"@/lib/utils\";\nimport type { LLMSettings } from \"@/lib/llm-settings\";\n\n// Setup fetch mock\nglobal.fetch = jest.fn() as any;\nconst mockFetch = global.fetch as Mock;\n\n// Mock setTimeout for retry tests\nconst originalSetTimeout = global.setTimeout;\nglobal.setTimeout = jest.fn((fn: Function, delay: number) => {\n  fn();\n  return 123 as any;\n}) as any;\n\ndescribe(\"lib/llm-service.ts - Complete Coverage\", () => {\n  beforeEach(() => {\n    jest.clearAllMocks();\n    mockFetch.mockClear();\n  });\n\n  afterAll(() => {\n    global.setTimeout = originalSetTimeout;\n  });\n\n  describe(\"withRetry function\", () => {\n    test(\"executes operation successfully on first try\", async () => {\n      const mockOperation = jest.fn().mockResolvedValue(\"success\");\n\n      const result = await withRetry(mockOperation);\n\n      expect(result).toBe(\"success\");\n      expect(mockOperation).toHaveBeenCalledTimes(1);\n    });\n\n    test(\"retries on failure and succeeds\", async () => {\n      const mockOperation = jest\n        .fn()\n        .mockRejectedValueOnce(new Error(\"First failure\"))\n        .mockResolvedValueOnce(\"success\");\n\n      const result = await withRetry(mockOperation, 2, 100);\n\n      expect(result).toBe(\"success\");\n      expect(mockOperation).toHaveBeenCalledTimes(2);\n      expect(setTimeout).toHaveBeenCalledWith(expect.any(Function), 100);\n    });\n\n    test(\"throws after max retries\", async () => {\n      const mockOperation = jest\n        .fn()\n        .mockRejectedValue(new Error(\"Persistent failure\"));\n\n      await expect(withRetry(mockOperation, 2, 100)).rejects.toThrow(\n        \"Persistent failure\",\n      );\n      expect(mockOperation).toHaveBeenCalledTimes(3); // Initial + 2 retries\n    });\n\n    test(\"handles non-Error exceptions\", async () => {\n      const mockOperation = jest.fn().mockRejectedValue(\"String error\");\n\n      await expect(withRetry(mockOperation, 1, 100)).rejects.toThrow(\n        \"String error\",\n      );\n      expect(mockOperation).toHaveBeenCalledTimes(2);\n    });\n\n    test(\"uses exponential backoff\", async () => {\n      const mockOperation = jest\n        .fn()\n        .mockRejectedValueOnce(new Error(\"Fail 1\"))\n        .mockRejectedValueOnce(new Error(\"Fail 2\"))\n        .mockResolvedValueOnce(\"success\");\n\n      await withRetry(mockOperation, 3, 100);\n\n      expect(setTimeout).toHaveBeenNthCalledWith(1, expect.any(Function), 100);\n      expect(setTimeout).toHaveBeenNthCalledWith(2, expect.any(Function), 200);\n    });\n\n    test(\"handles operation with no retries\", async () => {\n      const mockOperation = jest.fn().mockRejectedValue(new Error(\"Fail\"));\n\n      await expect(withRetry(mockOperation, 0, 100)).rejects.toThrow(\"Fail\");\n      expect(mockOperation).toHaveBeenCalledTimes(1);\n    });\n  });\n\n  describe(\"generateResponse function\", () => {\n    test(\"generates response with OpenAI provider\", async () => {\n      (generateText as Mock).mockResolvedValue({ text: \"AI response\" });\n\n      const result = await generateResponse(\"user prompt\", \"system prompt\", {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n      });\n\n      expect(result).toBe(\"AI response\");\n      expect(mockGenerateText).toHaveBeenCalledWith({\n        model: expect.objectContaining({\n          modelId: \"gpt-4\",\n          provider: \"openai\",\n        }),\n        system: \"system prompt\",\n        prompt: \"user prompt\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      });\n    });\n\n    test(\"generates response with OpenRouter provider\", async () => {\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        json: async () => ({\n          choices: [{ message: { content: \"OpenRouter response\" } }],\n        }),\n      });\n\n      const result = await generateResponse(\"user prompt\", \"system prompt\", {\n        provider: \"openrouter\",\n        apiKey: \"test-router-key\",\n        model: \"claude-3-opus\",\n      });\n\n      expect(result).toBe(\"OpenRouter response\");\n      expect(mockFetch).toHaveBeenCalledWith(\n        \"https://openrouter.ai/api/v1/chat/completions\",\n        expect.objectContaining({\n          method: \"POST\",\n          headers: expect.objectContaining({\n            \"Content-Type\": \"application/json\",\n            Authorization: \"Bearer test-router-key\",\n          }),\n        }),\n      );\n    });\n\n    test(\"handles missing API key\", async () => {\n      await expect(\n        generateResponse(\"user prompt\", \"system prompt\", {\n          provider: \"openai\",\n        }),\n      ).rejects.toThrow(\"API key required for openai\");\n    });\n\n    test(\"handles unsupported provider\", async () => {\n      await expect(\n        generateResponse(\"user prompt\", \"system prompt\", {\n          provider: \"unsupported\" as any,\n          apiKey: \"test-key\",\n        }),\n      ).rejects.toThrow(\"Unsupported provider: unsupported\");\n    });\n\n    test(\"handles OpenRouter API error\", async () => {\n      mockFetch.mockResolvedValueOnce({\n        ok: false,\n        status: 401,\n        statusText: \"Unauthorized\",\n        text: async () => '{\"error\": {\"message\": \"Invalid API key\"}}',\n      });\n\n      await expect(\n        generateResponse(\"user prompt\", \"system prompt\", {\n          provider: \"openrouter\",\n          apiKey: \"invalid-key\",\n          model: \"claude-3-opus\",\n        }),\n      ).rejects.toThrow(\"OpenRouter API error: 401 Unauthorized\");\n    });\n\n    test(\"handles OpenRouter non-JSON error response\", async () => {\n      mockFetch.mockResolvedValueOnce({\n        ok: false,\n        status: 500,\n        statusText: \"Internal Server Error\",\n        text: async () => \"Server error: Database connection failed\",\n      });\n\n      await expect(\n        generateResponse(\"user prompt\", \"system prompt\", {\n          provider: \"openrouter\",\n          apiKey: \"test-key\",\n          model: \"claude-3-opus\",\n        }),\n      ).rejects.toThrow(\"OpenRouter API error: 500 Internal Server Error\");\n    });\n\n    test(\"defaults to openai provider when not specified\", async () => {\n      const mockGenerateText = generateText as Mock;\n      mockGenerateText.mockResolvedValue({ text: \"Default response\" });\n\n      const result = await generateResponse(\"user prompt\", \"system prompt\", {\n        apiKey: \"test-key\",\n      });\n\n      expect(result).toBe(\"Default response\");\n    });\n\n    test(\"merges settings with defaults\", async () => {\n      const mockGenerateText = generateText as Mock;\n      mockGenerateText.mockResolvedValue({ text: \"Custom settings response\" });\n\n      await generateResponse(\"user prompt\", \"system prompt\", {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        temperature: 0.9,\n        maxTokens: 3000,\n      });\n\n      expect(mockGenerateText).toHaveBeenCalledWith(\n        expect.objectContaining({\n          temperature: 0.9,\n          maxTokens: 3000,\n          topP: 1, // From defaults\n          frequencyPenalty: 0, // From defaults\n          presencePenalty: 0, // From defaults\n        }),\n      );\n    });\n\n    test(\"handles OpenRouter with retry on failure\", async () => {\n      mockFetch\n        .mockRejectedValueOnce(new Error(\"Network error\"))\n        .mockResolvedValueOnce({\n          ok: true,\n          json: async () => ({\n            choices: [{ message: { content: \"Retry success\" } }],\n          }),\n        });\n\n      const result = await generateResponse(\"user prompt\", \"system prompt\", {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n      });\n\n      expect(result).toBe(\"Retry success\");\n      expect(mockFetch).toHaveBeenCalledTimes(2);\n    });\n  });\n\n  describe(\"streamGenerateResponse function\", () => {\n    test(\"streams response with OpenAI provider\", async () => {\n      const mockStreamText = streamText as Mock;\n      const mockTextStream = {\n        [Symbol.asyncIterator]: async function* () {\n          yield \"Hello \";\n          yield \"world\";\n        },\n      };\n      mockStreamText.mockResolvedValue({ textStream: mockTextStream });\n\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toEqual([\n        { text: \"Hello \", isComplete: false },\n        { text: \"world\", isComplete: false },\n        { text: \"\", isComplete: true },\n      ]);\n    });\n\n    test(\"handles missing API key in streaming\", async () => {\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toEqual([\n        {\n          text: \"Error: API key is required for openai provider\",\n          isComplete: true,\n        },\n      ]);\n    });\n\n    test(\"handles OpenAI streaming error with fallback\", async () => {\n      // Streaming fails\n      (streamText as Mock).mockRejectedValue(new Error(\"Stream error\"));\n      // Fallback succeeds\n      (generateText as Mock).mockResolvedValue({ text: \"Fallback response\" });\n\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toEqual([\n        { text: \"Fallback response\", isComplete: false },\n        { text: \"\", isComplete: true },\n      ]);\n    });\n\n    test(\"streams response with OpenRouter provider\", async () => {\n      const mockStream = new ReadableStream({\n        start(controller) {\n          controller.enqueue(\n            new TextEncoder().encode(\n              'data: {\"choices\":[{\"delta\":{\"content\":\"Hello \"}}]}\\n',\n            ),\n          );\n          controller.enqueue(\n            new TextEncoder().encode(\n              'data: {\"choices\":[{\"delta\":{\"content\":\"from \"}}]}\\n',\n            ),\n          );\n          controller.enqueue(\n            new TextEncoder().encode(\n              'data: {\"choices\":[{\"delta\":{\"content\":\"OpenRouter\"}}]}\\n',\n            ),\n          );\n          controller.enqueue(new TextEncoder().encode(\"data: [DONE]\\n\"));\n          controller.close();\n        },\n      });\n\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        body: mockStream,\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-router-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toEqual([\n        { text: \"Hello \", isComplete: false },\n        { text: \"from \", isComplete: false },\n        { text: \"OpenRouter\", isComplete: false },\n        { text: \"\", isComplete: true },\n      ]);\n    });\n\n    test(\"handles OpenRouter streaming error with fallback\", async () => {\n      // First call fails\n      mockFetch.mockRejectedValueOnce(new Error(\"Stream failed\"));\n      // Fallback call succeeds\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        json: async () => ({\n          choices: [{ message: { content: \"Fallback OpenRouter response\" } }],\n        }),\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toEqual([\n        { text: \"Fallback OpenRouter response\", isComplete: false },\n        { text: \"\", isComplete: true },\n      ]);\n    });\n\n    test(\"handles OpenRouter API error in streaming\", async () => {\n      mockFetch.mockResolvedValueOnce({\n        ok: false,\n        status: 403,\n        statusText: \"Forbidden\",\n        text: async () => \"API quota exceeded\",\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks[0].text).toContain(\"Error:\");\n      expect(chunks[0].text).toContain(\"OpenRouter API error: 403 Forbidden\");\n      expect(chunks[0].isComplete).toBe(true);\n    });\n\n    test(\"handles null response body in OpenRouter streaming\", async () => {\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        body: null,\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      // Should fallback to non-streaming\n      expect(mockFetch).toHaveBeenCalledTimes(1);\n      expect(chunks[0].text).toContain(\"Error:\");\n    });\n\n    test(\"handles malformed streaming data\", async () => {\n      const mockStream = new ReadableStream({\n        start(controller) {\n          controller.enqueue(new TextEncoder().encode(\"data: invalid json\\n\"));\n          controller.enqueue(\n            new TextEncoder().encode(\n              'data: {\"choices\":[{\"delta\":{\"content\":\"Valid\"}}]}\\n',\n            ),\n          );\n          controller.close();\n        },\n      });\n\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        body: mockStream,\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      // Should skip invalid JSON and continue\n      expect(chunks).toContainEqual({ text: \"Valid\", isComplete: false });\n    });\n\n    test(\"handles unsupported provider in streaming\", async () => {\n      const settings: LLMSettings = {\n        provider: \"unsupported\" as any,\n        apiKey: \"test-key\",\n        model: \"some-model\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toEqual([\n        {\n          text: \"Error: Unsupported provider: unsupported\",\n          isComplete: true,\n        },\n      ]);\n    });\n\n    test(\"handles general error in streaming\", async () => {\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: null as any, // Force an error\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      // Mock to throw an error\n      (streamText as Mock).mockImplementation(() => {\n        throw new TypeError(\"Cannot read properties of null\");\n      });\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks[0].text).toContain(\"Error:\");\n      expect(chunks[0].isComplete).toBe(true);\n    });\n  });\n\n  describe(\"validateResponse function\", () => {\n    test(\"validates valid response\", async () => {\n      const result = await validateResponse(\n        \"This is a valid response with sufficient content.\",\n      );\n      expect(result).toEqual({ valid: true });\n    });\n\n    test(\"rejects empty response\", async () => {\n      const result = await validateResponse(\"\");\n      expect(result).toEqual({ valid: false, reason: \"Empty response\" });\n    });\n\n    test(\"rejects whitespace-only response\", async () => {\n      const result = await validateResponse(\"   \\n\\t  \");\n      expect(result).toEqual({ valid: false, reason: \"Empty response\" });\n    });\n\n    test(\"rejects response with API error message\", async () => {\n      const result = await validateResponse(\"Error: API key is invalid\");\n      expect(result).toEqual({\n        valid: false,\n        reason: \"Response contains error messages\",\n      });\n    });\n\n    test(\"rejects response with key error message\", async () => {\n      const result = await validateResponse(\"ERROR: Missing API KEY\");\n      expect(result).toEqual({\n        valid: false,\n        reason: \"Response contains error messages\",\n      });\n    });\n\n    test(\"rejects too short response\", async () => {\n      const result = await validateResponse(\"Short\");\n      expect(result).toEqual({ valid: false, reason: \"Response too short\" });\n    });\n\n    test(\"accepts response at minimum length\", async () => {\n      const result = await validateResponse(\"Valid text\");\n      expect(result).toEqual({ valid: true });\n    });\n\n    test(\"accepts response with error word but not API/key related\", async () => {\n      const result = await validateResponse(\n        \"There was an error in judgment, but we corrected it.\",\n      );\n      expect(result).toEqual({ valid: true });\n    });\n  });\n\n  describe(\"extractBeliefs function\", () => {\n    test(\"extracts beliefs from conversation\", async () => {\n      // Mock generateText since extractBeliefs calls generateResponse\n      (generateText as Mock).mockResolvedValue({\n        text:\n          \"- Alice believes that [[quantum computing]] will revolutionize [[cryptography]] within the next decade. (High)\\n\" +\n          \"- Alice seems to prefer [[coffee]] over [[tea]] based on their ordering habits. (Medium)\",\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const result = await extractBeliefs(\n        \"Alice: I think quantum computing will change everything, especially cryptography.\",\n        \"Alice\",\n        \"technology opinions\",\n        settings,\n      );\n\n      expect(result).toContain(\"quantum computing\");\n      expect(result).toContain(\"cryptography\");\n    });\n\n    test(\"handles extraction error\", async () => {\n      (generateText as Mock).mockRejectedValue(new Error(\"LLM error\"));\n\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      await expect(\n        extractBeliefs(\"conversation\", \"Agent\", \"priorities\", settings),\n      ).rejects.toThrow(\"LLM error\");\n    });\n  });\n\n  describe(\"generateKnowledgeEntries function\", () => {\n    test(\"generates entries from beliefs\", async () => {\n      const beliefs =\n        \"- Agent believes that [[AI]] will transform [[healthcare]]. (High)\\n\" +\n        \"- Agent thinks [[blockchain]] is overhyped. (Medium)\\n\" +\n        \"Not a belief line\\n\" +\n        \"- Agent prefers [[Python]] for [[machine learning]]. (High)\";\n\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const entries = await generateKnowledgeEntries(beliefs, settings);\n\n      expect(entries).toHaveLength(3);\n      expect(entries[0].title).toBe(\"Knowledge about AI\");\n      expect(entries[0].tags).toEqual([\"AI\", \"healthcare\"]);\n      expect(entries[1].title).toBe(\"Knowledge about blockchain\");\n      expect(entries[1].tags).toEqual([\"blockchain\"]);\n      expect(entries[2].title).toBe(\"Knowledge about Python\");\n      expect(entries[2].tags).toEqual([\"Python\", \"machine learning\"]);\n    });\n\n    test(\"handles beliefs without tags\", async () => {\n      const beliefs = \"- Agent believes something without tags. (Low)\";\n\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const entries = await generateKnowledgeEntries(beliefs, settings);\n\n      expect(entries).toHaveLength(1);\n      expect(entries[0].title).toBe(\"Agent believes something\");\n      expect(entries[0].tags).toEqual([]);\n    });\n\n    test(\"handles empty beliefs\", async () => {\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const entries = await generateKnowledgeEntries(\"\", settings);\n      expect(entries).toHaveLength(0);\n    });\n\n    test(\"handles error during generation\", async () => {\n      // Mock extractTagsFromMarkdown to throw\n      const mockExtractTags = extractTagsFromMarkdown as Mock;\n      mockExtractTags.mockImplementation(() => {\n        throw new Error(\"Tag extraction failed\");\n      });\n\n      const beliefs = \"- Agent believes something. (High)\";\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const entries = await generateKnowledgeEntries(beliefs, settings);\n\n      expect(entries).toHaveLength(1);\n      expect(entries[0].title).toBe(\"Error\");\n      expect(entries[0].content).toBe(\"Tag extraction failed\");\n      expect(entries[0].tags).toEqual([\"error\"]);\n    });\n  });\n\n  describe(\"validateApiKey function\", () => {\n    test(\"validates OpenAI API key\", async () => {\n      const result = await validateApiKey(\"openai\", \"sk-test123\");\n      expect(result).toEqual({\n        valid: true,\n        message: \"API key validation successful for openai. (This is a mock)\",\n      });\n    });\n\n    test(\"validates OpenRouter API key\", async () => {\n      const result = await validateApiKey(\"openrouter\", \"or-test123\");\n      expect(result).toEqual({\n        valid: true,\n        message:\n          \"API key validation successful for openrouter. (This is a mock)\",\n      });\n    });\n  });\n\n  describe(\"saveLLMSettings function\", () => {\n    test(\"saves settings successfully\", async () => {\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.8,\n        maxTokens: 3000,\n        topP: 0.9,\n        frequencyPenalty: 0.1,\n        presencePenalty: 0.1,\n      };\n\n      const result = await saveLLMSettings(settings);\n      expect(result).toBe(true);\n    });\n\n    test(\"handles save error gracefully\", async () => {\n      const settings: LLMSettings = {\n        provider: \"openai\",\n        apiKey: \"test-key\",\n        model: \"gpt-4\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      // Since saveLLMSettings is a mock that always returns true, we expect true\n      const result = await saveLLMSettings(settings);\n      expect(result).toBe(true);\n    });\n  });\n\n  describe(\"Edge cases and error handling\", () => {\n    test(\"handles timeout in OpenRouter calls\", async () => {\n      const mockWithTimeout = withTimeout as Mock;\n      mockWithTimeout.mockRejectedValue(new Error(\"Request timeout\"));\n\n      await expect(\n        generateResponse(\"user prompt\", \"system prompt\", {\n          provider: \"openrouter\",\n          apiKey: \"test-key\",\n          model: \"claude-3-opus\",\n        }),\n      ).rejects.toThrow(\"Request timeout\");\n    });\n\n    test(\"handles timeout in OpenAI calls\", async () => {\n      const mockWithTimeout = withTimeout as Mock;\n      mockWithTimeout.mockRejectedValue(new Error(\"OpenAI timeout\"));\n\n      await expect(\n        generateResponse(\"user prompt\", \"system prompt\", {\n          provider: \"openai\",\n          apiKey: \"test-key\",\n          model: \"gpt-4\",\n        }),\n      ).rejects.toThrow(\"OpenAI timeout\");\n    });\n\n    test(\"handles partial streaming data\", async () => {\n      const mockStream = new ReadableStream({\n        start(controller) {\n          // Send partial data that gets buffered\n          controller.enqueue(\n            new TextEncoder().encode('data: {\"choices\":[{\"delta\":'),\n          );\n          controller.enqueue(new TextEncoder().encode('{\"content\":\"Partial\"}'));\n          controller.enqueue(new TextEncoder().encode(\"}]}\\n\"));\n          controller.close();\n        },\n      });\n\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        body: mockStream,\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      expect(chunks).toContainEqual({ text: \"Partial\", isComplete: false });\n    });\n\n    test(\"handles streaming with no content in delta\", async () => {\n      const mockStream = new ReadableStream({\n        start(controller) {\n          controller.enqueue(\n            new TextEncoder().encode('data: {\"choices\":[{\"delta\":{}}]}\\n'),\n          );\n          controller.enqueue(\n            new TextEncoder().encode(\n              'data: {\"choices\":[{\"delta\":{\"role\":\"assistant\"}}]}\\n',\n            ),\n          );\n          controller.close();\n        },\n      });\n\n      mockFetch.mockResolvedValueOnce({\n        ok: true,\n        body: mockStream,\n      });\n\n      const settings: LLMSettings = {\n        provider: \"openrouter\",\n        apiKey: \"test-key\",\n        model: \"claude-3-opus\",\n        temperature: 0.7,\n        maxTokens: 2000,\n        topP: 1,\n        frequencyPenalty: 0,\n        presencePenalty: 0,\n      };\n\n      const chunks: StreamChunk[] = [];\n      for await (const chunk of streamGenerateResponse(\n        \"system\",\n        \"user\",\n        settings,\n      )) {\n        chunks.push(chunk);\n      }\n\n      // Should only have the completion chunk\n      expect(chunks).toEqual([{ text: \"\", isComplete: true }]);\n    });\n  });\n});\n"],"names":["jest","mock","openai","fn","model","modelId","provider","createOpenAI","config","apiKey","streamText","generateText","notFound","createLogger","info","error","warn","debug","debugLog","originalModule","requireActual","withTimeout","promise","timeout","message","extractTagsFromMarkdown","text","matches","match","map","m","slice","defaultSettings","temperature","maxTokens","topP","frequencyPenalty","presencePenalty","global","fetch","mockFetch","originalSetTimeout","setTimeout","delay","describe","beforeEach","clearAllMocks","mockClear","afterAll","test","mockOperation","mockResolvedValue","result","withRetry","expect","toBe","toHaveBeenCalledTimes","mockRejectedValueOnce","Error","mockResolvedValueOnce","toHaveBeenCalledWith","any","Function","mockRejectedValue","rejects","toThrow","toHaveBeenNthCalledWith","generateResponse","mockGenerateText","objectContaining","system","prompt","ok","json","choices","content","method","headers","Authorization","status","statusText","mockStreamText","mockTextStream","Symbol","asyncIterator","textStream","settings","chunks","chunk","streamGenerateResponse","push","toEqual","isComplete","mockStream","ReadableStream","start","controller","enqueue","TextEncoder","encode","close","body","toContain","toContainEqual","mockImplementation","TypeError","validateResponse","valid","reason","extractBeliefs","beliefs","entries","generateKnowledgeEntries","toHaveLength","title","tags","mockExtractTags","validateApiKey","saveLLMSettings","mockWithTimeout"],"mappings":"AAAA;;;;CAIC;;;;yBAEoB;4BA4Ed;oBAEkC;2BAEb;uBACY;AA9ExC,sDAAsD;AACtDA,aAAI,CAACC,IAAI,CAAC,kBAAkB,IAAO,CAAA;QACjCC,QAAQF,aAAI,CAACG,EAAE,CAAC,CAACC,QAAmB,CAAA;gBAClCC,SAASD;gBACTE,UAAU;YACZ,CAAA;QACAC,cAAcP,aAAI,CAACG,EAAE,CAAC,CAACK;YACrB,OAAO,CAACJ,QAAmB,CAAA;oBACzBC,SAASD;oBACTE,UAAU;oBACVG,QAAQD,OAAOC,MAAM;gBACvB,CAAA;QACF;IACF,CAAA;AAEAT,aAAI,CAACC,IAAI,CAAC,MAAM,IAAO,CAAA;QACrBS,YAAYV,aAAI,CAACG,EAAE;QACnBQ,cAAcX,aAAI,CAACG,EAAE;IACvB,CAAA;AAEAH,aAAI,CAACC,IAAI,CAAC,mBAAmB,IAAO,CAAA;QAClCW,UAAUZ,aAAI,CAACG,EAAE;IACnB,CAAA;AAEAH,aAAI,CAACC,IAAI,CAAC,sBAAsB,IAAO,CAAA;QACrCY,cAAcb,aAAI,CAACG,EAAE,CAAC,IAAO,CAAA;gBAC3BW,MAAMd,aAAI,CAACG,EAAE;gBACbY,OAAOf,aAAI,CAACG,EAAE;gBACda,MAAMhB,aAAI,CAACG,EAAE;gBACbc,OAAOjB,aAAI,CAACG,EAAE;YAChB,CAAA;QACAe,UAAUlB,aAAI,CAACG,EAAE;IACnB,CAAA;AAEAH,aAAI,CAACC,IAAI,CAAC,oBAAoB;IAC5B,MAAMkB,iBAAiBnB,aAAI,CAACoB,aAAa,CAAC;IAC1C,OAAO;QACL,GAAGD,cAAc;QACjBE,aAAarB,aAAI,CAACG,EAAE,CAAC,CAACmB,SAASC,SAASC,UAAYF;IACtD;AACF;AAEAtB,aAAI,CAACC,IAAI,CAAC,eAAe,IAAO,CAAA;QAC9BwB,yBAAyBzB,aAAI,CAACG,EAAE,CAAC,CAACuB;YAChC,MAAMC,UAAUD,KAAKE,KAAK,CAAC;YAC3B,OAAOD,UAAUA,QAAQE,GAAG,CAAC,CAACC,IAAMA,EAAEC,KAAK,CAAC,GAAG,CAAC,MAAM,EAAE;QAC1D;IACF,CAAA;AAEA/B,aAAI,CAACC,IAAI,CAAC,sBAAsB,IAAO,CAAA;QACrC+B,iBAAiB;YACf1B,UAAU;YACVF,OAAO;YACPK,QAAQ;YACRwB,aAAa;YACbC,WAAW;YACXC,MAAM;YACNC,kBAAkB;YAClBC,iBAAiB;QACnB;IACF,CAAA;AAqBA,mBAAmB;AACnBC,OAAOC,KAAK,GAAGvC,aAAI,CAACG,EAAE;AACtB,MAAMqC,YAAYF,OAAOC,KAAK;AAE9B,kCAAkC;AAClC,MAAME,qBAAqBH,OAAOI,UAAU;AAC5CJ,OAAOI,UAAU,GAAG1C,aAAI,CAACG,EAAE,CAAC,CAACA,IAAcwC;IACzCxC;IACA,OAAO;AACT;AAEAyC,SAAS,0CAA0C;IACjDC,WAAW;QACT7C,aAAI,CAAC8C,aAAa;QAClBN,UAAUO,SAAS;IACrB;IAEAC,SAAS;QACPV,OAAOI,UAAU,GAAGD;IACtB;IAEAG,SAAS,sBAAsB;QAC7BK,KAAK,gDAAgD;YACnD,MAAMC,gBAAgBlD,aAAI,CAACG,EAAE,GAAGgD,iBAAiB,CAAC;YAElD,MAAMC,SAAS,MAAMC,IAAAA,qBAAS,EAACH;YAE/BI,OAAOF,QAAQG,IAAI,CAAC;YACpBD,OAAOJ,eAAeM,qBAAqB,CAAC;QAC9C;QAEAP,KAAK,mCAAmC;YACtC,MAAMC,gBAAgBlD,aAAI,CACvBG,EAAE,GACFsD,qBAAqB,CAAC,IAAIC,MAAM,kBAChCC,qBAAqB,CAAC;YAEzB,MAAMP,SAAS,MAAMC,IAAAA,qBAAS,EAACH,eAAe,GAAG;YAEjDI,OAAOF,QAAQG,IAAI,CAAC;YACpBD,OAAOJ,eAAeM,qBAAqB,CAAC;YAC5CF,OAAOZ,YAAYkB,oBAAoB,CAACN,OAAOO,GAAG,CAACC,WAAW;QAChE;QAEAb,KAAK,4BAA4B;YAC/B,MAAMC,gBAAgBlD,aAAI,CACvBG,EAAE,GACF4D,iBAAiB,CAAC,IAAIL,MAAM;YAE/B,MAAMJ,OAAOD,IAAAA,qBAAS,EAACH,eAAe,GAAG,MAAMc,OAAO,CAACC,OAAO,CAC5D;YAEFX,OAAOJ,eAAeM,qBAAqB,CAAC,IAAI,sBAAsB;QACxE;QAEAP,KAAK,gCAAgC;YACnC,MAAMC,gBAAgBlD,aAAI,CAACG,EAAE,GAAG4D,iBAAiB,CAAC;YAElD,MAAMT,OAAOD,IAAAA,qBAAS,EAACH,eAAe,GAAG,MAAMc,OAAO,CAACC,OAAO,CAC5D;YAEFX,OAAOJ,eAAeM,qBAAqB,CAAC;QAC9C;QAEAP,KAAK,4BAA4B;YAC/B,MAAMC,gBAAgBlD,aAAI,CACvBG,EAAE,GACFsD,qBAAqB,CAAC,IAAIC,MAAM,WAChCD,qBAAqB,CAAC,IAAIC,MAAM,WAChCC,qBAAqB,CAAC;YAEzB,MAAMN,IAAAA,qBAAS,EAACH,eAAe,GAAG;YAElCI,OAAOZ,YAAYwB,uBAAuB,CAAC,GAAGZ,OAAOO,GAAG,CAACC,WAAW;YACpER,OAAOZ,YAAYwB,uBAAuB,CAAC,GAAGZ,OAAOO,GAAG,CAACC,WAAW;QACtE;QAEAb,KAAK,qCAAqC;YACxC,MAAMC,gBAAgBlD,aAAI,CAACG,EAAE,GAAG4D,iBAAiB,CAAC,IAAIL,MAAM;YAE5D,MAAMJ,OAAOD,IAAAA,qBAAS,EAACH,eAAe,GAAG,MAAMc,OAAO,CAACC,OAAO,CAAC;YAC/DX,OAAOJ,eAAeM,qBAAqB,CAAC;QAC9C;IACF;IAEAZ,SAAS,6BAA6B;QACpCK,KAAK,2CAA2C;YAC7CtC,gBAAY,CAAUwC,iBAAiB,CAAC;gBAAEzB,MAAM;YAAc;YAE/D,MAAM0B,SAAS,MAAMe,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBACpE7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT;YAEAkD,OAAOF,QAAQG,IAAI,CAAC;YACpBD,OAAOc,kBAAkBR,oBAAoB,CAAC;gBAC5CxD,OAAOkD,OAAOe,gBAAgB,CAAC;oBAC7BhE,SAAS;oBACTC,UAAU;gBACZ;gBACAgE,QAAQ;gBACRC,QAAQ;gBACRtC,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;QACF;QAEAY,KAAK,+CAA+C;YAClDT,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJC,MAAM,UAAa,CAAA;wBACjBC,SAAS;4BAAC;gCAAElD,SAAS;oCAAEmD,SAAS;gCAAsB;4BAAE;yBAAE;oBAC5D,CAAA;YACF;YAEA,MAAMvB,SAAS,MAAMe,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBACpE7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT;YAEAkD,OAAOF,QAAQG,IAAI,CAAC;YACpBD,OAAOd,WAAWoB,oBAAoB,CACpC,iDACAN,OAAOe,gBAAgB,CAAC;gBACtBO,QAAQ;gBACRC,SAASvB,OAAOe,gBAAgB,CAAC;oBAC/B,gBAAgB;oBAChBS,eAAe;gBACjB;YACF;QAEJ;QAEA7B,KAAK,2BAA2B;YAC9B,MAAMK,OACJa,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBAC/C7D,UAAU;YACZ,IACA0D,OAAO,CAACC,OAAO,CAAC;QACpB;QAEAhB,KAAK,gCAAgC;YACnC,MAAMK,OACJa,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBAC/C7D,UAAU;gBACVG,QAAQ;YACV,IACAuD,OAAO,CAACC,OAAO,CAAC;QACpB;QAEAhB,KAAK,gCAAgC;YACnCT,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJO,QAAQ;gBACRC,YAAY;gBACZtD,MAAM,UAAY;YACpB;YAEA,MAAM4B,OACJa,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBAC/C7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT,IACA4D,OAAO,CAACC,OAAO,CAAC;QACpB;QAEAhB,KAAK,8CAA8C;YACjDT,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJO,QAAQ;gBACRC,YAAY;gBACZtD,MAAM,UAAY;YACpB;YAEA,MAAM4B,OACJa,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBAC/C7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT,IACA4D,OAAO,CAACC,OAAO,CAAC;QACpB;QAEAhB,KAAK,kDAAkD;YACrD,MAAMmB,oBAAmBzD,gBAAY;YACrCyD,kBAAiBjB,iBAAiB,CAAC;gBAAEzB,MAAM;YAAmB;YAE9D,MAAM0B,SAAS,MAAMe,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBACpE1D,QAAQ;YACV;YAEA6C,OAAOF,QAAQG,IAAI,CAAC;QACtB;QAEAN,KAAK,iCAAiC;YACpC,MAAMmB,oBAAmBzD,gBAAY;YACrCyD,kBAAiBjB,iBAAiB,CAAC;gBAAEzB,MAAM;YAA2B;YAEtE,MAAMyC,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBACrD7D,UAAU;gBACVG,QAAQ;gBACRwB,aAAa;gBACbC,WAAW;YACb;YAEAoB,OAAOc,mBAAkBR,oBAAoB,CAC3CN,OAAOe,gBAAgB,CAAC;gBACtBpC,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;QAEJ;QAEAY,KAAK,4CAA4C;YAC/CT,UACGiB,qBAAqB,CAAC,IAAIC,MAAM,kBAChCC,qBAAqB,CAAC;gBACrBa,IAAI;gBACJC,MAAM,UAAa,CAAA;wBACjBC,SAAS;4BAAC;gCAAElD,SAAS;oCAAEmD,SAAS;gCAAgB;4BAAE;yBAAE;oBACtD,CAAA;YACF;YAEF,MAAMvB,SAAS,MAAMe,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBACpE7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT;YAEAkD,OAAOF,QAAQG,IAAI,CAAC;YACpBD,OAAOd,WAAWgB,qBAAqB,CAAC;QAC1C;IACF;IAEAZ,SAAS,mCAAmC;QAC1CK,KAAK,yCAAyC;YAC5C,MAAMgC,iBAAiBvE,cAAU;YACjC,MAAMwE,iBAAiB;gBACrB,CAACC,OAAOC,aAAa,CAAC,EAAE;oBACtB,MAAM;oBACN,MAAM;gBACR;YACF;YACAH,eAAe9B,iBAAiB,CAAC;gBAAEkC,YAAYH;YAAe;YAE9D,MAAMI,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQI,OAAO,CAAC;gBACrB;oBAAEjE,MAAM;oBAAUkE,YAAY;gBAAM;gBACpC;oBAAElE,MAAM;oBAASkE,YAAY;gBAAM;gBACnC;oBAAElE,MAAM;oBAAIkE,YAAY;gBAAK;aAC9B;QACH;QAEA3C,KAAK,wCAAwC;YAC3C,MAAMqC,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQI,OAAO,CAAC;gBACrB;oBACEjE,MAAM;oBACNkE,YAAY;gBACd;aACD;QACH;QAEA3C,KAAK,gDAAgD;YACnD,kBAAkB;YACjBvC,cAAU,CAAUqD,iBAAiB,CAAC,IAAIL,MAAM;YACjD,oBAAoB;YACnB/C,gBAAY,CAAUwC,iBAAiB,CAAC;gBAAEzB,MAAM;YAAoB;YAErE,MAAM4D,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQI,OAAO,CAAC;gBACrB;oBAAEjE,MAAM;oBAAqBkE,YAAY;gBAAM;gBAC/C;oBAAElE,MAAM;oBAAIkE,YAAY;gBAAK;aAC9B;QACH;QAEA3C,KAAK,6CAA6C;YAChD,MAAM4C,aAAa,IAAIC,eAAe;gBACpCC,OAAMC,UAAU;oBACdA,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CACtB;oBAGJH,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CACtB;oBAGJH,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CACtB;oBAGJH,WAAWC,OAAO,CAAC,IAAIC,cAAcC,MAAM,CAAC;oBAC5CH,WAAWI,KAAK;gBAClB;YACF;YAEA5D,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJ6B,MAAMR;YACR;YAEA,MAAMP,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQI,OAAO,CAAC;gBACrB;oBAAEjE,MAAM;oBAAUkE,YAAY;gBAAM;gBACpC;oBAAElE,MAAM;oBAASkE,YAAY;gBAAM;gBACnC;oBAAElE,MAAM;oBAAckE,YAAY;gBAAM;gBACxC;oBAAElE,MAAM;oBAAIkE,YAAY;gBAAK;aAC9B;QACH;QAEA3C,KAAK,oDAAoD;YACvD,mBAAmB;YACnBT,UAAUiB,qBAAqB,CAAC,IAAIC,MAAM;YAC1C,yBAAyB;YACzBlB,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJC,MAAM,UAAa,CAAA;wBACjBC,SAAS;4BAAC;gCAAElD,SAAS;oCAAEmD,SAAS;gCAA+B;4BAAE;yBAAE;oBACrE,CAAA;YACF;YAEA,MAAMW,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQI,OAAO,CAAC;gBACrB;oBAAEjE,MAAM;oBAAgCkE,YAAY;gBAAM;gBAC1D;oBAAElE,MAAM;oBAAIkE,YAAY;gBAAK;aAC9B;QACH;QAEA3C,KAAK,6CAA6C;YAChDT,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJO,QAAQ;gBACRC,YAAY;gBACZtD,MAAM,UAAY;YACpB;YAEA,MAAM4D,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,MAAM,CAAC,EAAE,CAAC7D,IAAI,EAAE4E,SAAS,CAAC;YACjChD,OAAOiC,MAAM,CAAC,EAAE,CAAC7D,IAAI,EAAE4E,SAAS,CAAC;YACjChD,OAAOiC,MAAM,CAAC,EAAE,CAACK,UAAU,EAAErC,IAAI,CAAC;QACpC;QAEAN,KAAK,sDAAsD;YACzDT,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJ6B,MAAM;YACR;YAEA,MAAMf,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEA,mCAAmC;YACnClC,OAAOd,WAAWgB,qBAAqB,CAAC;YACxCF,OAAOiC,MAAM,CAAC,EAAE,CAAC7D,IAAI,EAAE4E,SAAS,CAAC;QACnC;QAEArD,KAAK,oCAAoC;YACvC,MAAM4C,aAAa,IAAIC,eAAe;gBACpCC,OAAMC,UAAU;oBACdA,WAAWC,OAAO,CAAC,IAAIC,cAAcC,MAAM,CAAC;oBAC5CH,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CACtB;oBAGJH,WAAWI,KAAK;gBAClB;YACF;YAEA5D,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJ6B,MAAMR;YACR;YAEA,MAAMP,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEA,wCAAwC;YACxClC,OAAOiC,QAAQgB,cAAc,CAAC;gBAAE7E,MAAM;gBAASkE,YAAY;YAAM;QACnE;QAEA3C,KAAK,6CAA6C;YAChD,MAAMqC,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQI,OAAO,CAAC;gBACrB;oBACEjE,MAAM;oBACNkE,YAAY;gBACd;aACD;QACH;QAEA3C,KAAK,sCAAsC;YACzC,MAAMqC,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,yBAAyB;YACxB3B,cAAU,CAAU8F,kBAAkB,CAAC;gBACtC,MAAM,IAAIC,UAAU;YACtB;YAEA,MAAMlB,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,MAAM,CAAC,EAAE,CAAC7D,IAAI,EAAE4E,SAAS,CAAC;YACjChD,OAAOiC,MAAM,CAAC,EAAE,CAACK,UAAU,EAAErC,IAAI,CAAC;QACpC;IACF;IAEAX,SAAS,6BAA6B;QACpCK,KAAK,4BAA4B;YAC/B,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EACnC;YAEFpD,OAAOF,QAAQuC,OAAO,CAAC;gBAAEgB,OAAO;YAAK;QACvC;QAEA1D,KAAK,0BAA0B;YAC7B,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EAAC;YACtCpD,OAAOF,QAAQuC,OAAO,CAAC;gBAAEgB,OAAO;gBAAOC,QAAQ;YAAiB;QAClE;QAEA3D,KAAK,oCAAoC;YACvC,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EAAC;YACtCpD,OAAOF,QAAQuC,OAAO,CAAC;gBAAEgB,OAAO;gBAAOC,QAAQ;YAAiB;QAClE;QAEA3D,KAAK,2CAA2C;YAC9C,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EAAC;YACtCpD,OAAOF,QAAQuC,OAAO,CAAC;gBACrBgB,OAAO;gBACPC,QAAQ;YACV;QACF;QAEA3D,KAAK,2CAA2C;YAC9C,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EAAC;YACtCpD,OAAOF,QAAQuC,OAAO,CAAC;gBACrBgB,OAAO;gBACPC,QAAQ;YACV;QACF;QAEA3D,KAAK,8BAA8B;YACjC,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EAAC;YACtCpD,OAAOF,QAAQuC,OAAO,CAAC;gBAAEgB,OAAO;gBAAOC,QAAQ;YAAqB;QACtE;QAEA3D,KAAK,sCAAsC;YACzC,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EAAC;YACtCpD,OAAOF,QAAQuC,OAAO,CAAC;gBAAEgB,OAAO;YAAK;QACvC;QAEA1D,KAAK,4DAA4D;YAC/D,MAAMG,SAAS,MAAMsD,IAAAA,4BAAgB,EACnC;YAEFpD,OAAOF,QAAQuC,OAAO,CAAC;gBAAEgB,OAAO;YAAK;QACvC;IACF;IAEA/D,SAAS,2BAA2B;QAClCK,KAAK,sCAAsC;YACzC,gEAAgE;YAC/DtC,gBAAY,CAAUwC,iBAAiB,CAAC;gBACvCzB,MACE,qHACA;YACJ;YAEA,MAAM4D,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMe,SAAS,MAAMyD,IAAAA,0BAAc,EACjC,qFACA,SACA,uBACAvB;YAGFhC,OAAOF,QAAQkD,SAAS,CAAC;YACzBhD,OAAOF,QAAQkD,SAAS,CAAC;QAC3B;QAEArD,KAAK,4BAA4B;YAC9BtC,gBAAY,CAAUoD,iBAAiB,CAAC,IAAIL,MAAM;YAEnD,MAAM4B,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMiB,OACJuD,IAAAA,0BAAc,EAAC,gBAAgB,SAAS,cAAcvB,WACtDtB,OAAO,CAACC,OAAO,CAAC;QACpB;IACF;IAEArB,SAAS,qCAAqC;QAC5CK,KAAK,kCAAkC;YACrC,MAAM6D,UACJ,yEACA,2DACA,wBACA;YAEF,MAAMxB,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAM0E,UAAU,MAAMC,IAAAA,oCAAwB,EAACF,SAASxB;YAExDhC,OAAOyD,SAASE,YAAY,CAAC;YAC7B3D,OAAOyD,OAAO,CAAC,EAAE,CAACG,KAAK,EAAE3D,IAAI,CAAC;YAC9BD,OAAOyD,OAAO,CAAC,EAAE,CAACI,IAAI,EAAExB,OAAO,CAAC;gBAAC;gBAAM;aAAa;YACpDrC,OAAOyD,OAAO,CAAC,EAAE,CAACG,KAAK,EAAE3D,IAAI,CAAC;YAC9BD,OAAOyD,OAAO,CAAC,EAAE,CAACI,IAAI,EAAExB,OAAO,CAAC;gBAAC;aAAa;YAC9CrC,OAAOyD,OAAO,CAAC,EAAE,CAACG,KAAK,EAAE3D,IAAI,CAAC;YAC9BD,OAAOyD,OAAO,CAAC,EAAE,CAACI,IAAI,EAAExB,OAAO,CAAC;gBAAC;gBAAU;aAAmB;QAChE;QAEA1C,KAAK,gCAAgC;YACnC,MAAM6D,UAAU;YAEhB,MAAMxB,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAM0E,UAAU,MAAMC,IAAAA,oCAAwB,EAACF,SAASxB;YAExDhC,OAAOyD,SAASE,YAAY,CAAC;YAC7B3D,OAAOyD,OAAO,CAAC,EAAE,CAACG,KAAK,EAAE3D,IAAI,CAAC;YAC9BD,OAAOyD,OAAO,CAAC,EAAE,CAACI,IAAI,EAAExB,OAAO,CAAC,EAAE;QACpC;QAEA1C,KAAK,yBAAyB;YAC5B,MAAMqC,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAM0E,UAAU,MAAMC,IAAAA,oCAAwB,EAAC,IAAI1B;YACnDhC,OAAOyD,SAASE,YAAY,CAAC;QAC/B;QAEAhE,KAAK,mCAAmC;YACtC,wCAAwC;YACxC,MAAMmE,kBAAkB3F,8BAAuB;YAC/C2F,gBAAgBZ,kBAAkB,CAAC;gBACjC,MAAM,IAAI9C,MAAM;YAClB;YAEA,MAAMoD,UAAU;YAChB,MAAMxB,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAM0E,UAAU,MAAMC,IAAAA,oCAAwB,EAACF,SAASxB;YAExDhC,OAAOyD,SAASE,YAAY,CAAC;YAC7B3D,OAAOyD,OAAO,CAAC,EAAE,CAACG,KAAK,EAAE3D,IAAI,CAAC;YAC9BD,OAAOyD,OAAO,CAAC,EAAE,CAACpC,OAAO,EAAEpB,IAAI,CAAC;YAChCD,OAAOyD,OAAO,CAAC,EAAE,CAACI,IAAI,EAAExB,OAAO,CAAC;gBAAC;aAAQ;QAC3C;IACF;IAEA/C,SAAS,2BAA2B;QAClCK,KAAK,4BAA4B;YAC/B,MAAMG,SAAS,MAAMiE,IAAAA,0BAAc,EAAC,UAAU;YAC9C/D,OAAOF,QAAQuC,OAAO,CAAC;gBACrBgB,OAAO;gBACPnF,SAAS;YACX;QACF;QAEAyB,KAAK,gCAAgC;YACnC,MAAMG,SAAS,MAAMiE,IAAAA,0BAAc,EAAC,cAAc;YAClD/D,OAAOF,QAAQuC,OAAO,CAAC;gBACrBgB,OAAO;gBACPnF,SACE;YACJ;QACF;IACF;IAEAoB,SAAS,4BAA4B;QACnCK,KAAK,+BAA+B;YAClC,MAAMqC,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMe,SAAS,MAAMkE,IAAAA,2BAAe,EAAChC;YACrChC,OAAOF,QAAQG,IAAI,CAAC;QACtB;QAEAN,KAAK,iCAAiC;YACpC,MAAMqC,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,2EAA2E;YAC3E,MAAMe,SAAS,MAAMkE,IAAAA,2BAAe,EAAChC;YACrChC,OAAOF,QAAQG,IAAI,CAAC;QACtB;IACF;IAEAX,SAAS,iCAAiC;QACxCK,KAAK,uCAAuC;YAC1C,MAAMsE,kBAAkBlG,sBAAW;YACnCkG,gBAAgBxD,iBAAiB,CAAC,IAAIL,MAAM;YAE5C,MAAMJ,OACJa,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBAC/C7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT,IACA4D,OAAO,CAACC,OAAO,CAAC;QACpB;QAEAhB,KAAK,mCAAmC;YACtC,MAAMsE,kBAAkBlG,sBAAW;YACnCkG,gBAAgBxD,iBAAiB,CAAC,IAAIL,MAAM;YAE5C,MAAMJ,OACJa,IAAAA,4BAAgB,EAAC,eAAe,iBAAiB;gBAC/C7D,UAAU;gBACVG,QAAQ;gBACRL,OAAO;YACT,IACA4D,OAAO,CAACC,OAAO,CAAC;QACpB;QAEAhB,KAAK,kCAAkC;YACrC,MAAM4C,aAAa,IAAIC,eAAe;gBACpCC,OAAMC,UAAU;oBACd,uCAAuC;oBACvCA,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CAAC;oBAE3BH,WAAWC,OAAO,CAAC,IAAIC,cAAcC,MAAM,CAAC;oBAC5CH,WAAWC,OAAO,CAAC,IAAIC,cAAcC,MAAM,CAAC;oBAC5CH,WAAWI,KAAK;gBAClB;YACF;YAEA5D,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJ6B,MAAMR;YACR;YAEA,MAAMP,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEAlC,OAAOiC,QAAQgB,cAAc,CAAC;gBAAE7E,MAAM;gBAAWkE,YAAY;YAAM;QACrE;QAEA3C,KAAK,8CAA8C;YACjD,MAAM4C,aAAa,IAAIC,eAAe;gBACpCC,OAAMC,UAAU;oBACdA,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CAAC;oBAE3BH,WAAWC,OAAO,CAChB,IAAIC,cAAcC,MAAM,CACtB;oBAGJH,WAAWI,KAAK;gBAClB;YACF;YAEA5D,UAAUmB,qBAAqB,CAAC;gBAC9Ba,IAAI;gBACJ6B,MAAMR;YACR;YAEA,MAAMP,WAAwB;gBAC5BhF,UAAU;gBACVG,QAAQ;gBACRL,OAAO;gBACP6B,aAAa;gBACbC,WAAW;gBACXC,MAAM;gBACNC,kBAAkB;gBAClBC,iBAAiB;YACnB;YAEA,MAAMkD,SAAwB,EAAE;YAChC,WAAW,MAAMC,SAASC,IAAAA,kCAAsB,EAC9C,UACA,QACAH,UACC;gBACDC,OAAOG,IAAI,CAACF;YACd;YAEA,wCAAwC;YACxClC,OAAOiC,QAAQI,OAAO,CAAC;gBAAC;oBAAEjE,MAAM;oBAAIkE,YAAY;gBAAK;aAAE;QACzD;IACF;AACF"}