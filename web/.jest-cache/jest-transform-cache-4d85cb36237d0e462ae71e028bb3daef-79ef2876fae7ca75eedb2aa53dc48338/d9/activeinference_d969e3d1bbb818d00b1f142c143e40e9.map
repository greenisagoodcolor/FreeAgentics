{"version":3,"sources":["/Users/matthewmoroney/builds/FreeAgentics/web/lib/active-inference.ts"],"sourcesContent":["/**\n * Active Inference Implementation\n *\n * Core implementation for active inference, free energy minimization,\n * and belief updating based on the Free Energy Principle.\n */\n\nexport interface GenerativeModel {\n  states: string[];\n  observations: string[];\n  actions: string[];\n  transitionModel: Record<string, Record<string, Record<string, number>>>;\n  observationModel: Record<string, Record<string, number>>;\n  preferences: Record<string, number>;\n}\n\nexport interface Beliefs {\n  states: Record<string, number>;\n  uncertainty: number;\n  converged?: boolean;\n  iterations?: number;\n}\n\nexport interface SensoryInput {\n  type: string;\n  value: string;\n  confidence: number;\n}\n\nexport interface Action {\n  type: string;\n  confidence: number;\n  expectedOutcome?: string;\n}\n\nexport type Policy = Array<{\n  action: string;\n  timestep: number;\n}>;\n\nexport interface ActiveInferenceConfig {\n  model: GenerativeModel;\n  precision?: number;\n  learningRate?: number;\n  planningHorizon?: number;\n  actionConstraints?: Record<string, { maxFrequency: number }>;\n}\n\nexport interface ActiveInferenceEngine {\n  model: GenerativeModel;\n  precision: number;\n  learningRate: number;\n  planningHorizon: number;\n  actionConstraints?: Record<string, { maxFrequency: number }>;\n  beliefs: Beliefs;\n  actionHistory: string[];\n  getCurrentBeliefs: () => Beliefs;\n  setBeliefs: (beliefs: Beliefs) => void;\n  calculateFreeEnergy: (beliefs: Beliefs, observation: string) => number;\n}\n\nexport interface InferenceResult {\n  beliefs: Beliefs;\n  selectedAction: Action;\n  freeEnergy: number;\n  confidence: number;\n}\n\nexport interface ExpectedFreeEnergy {\n  total: number;\n  epistemic: number;\n  pragmatic: number;\n}\n\nexport interface PolicyEvaluation {\n  expectedReturn: number;\n  uncertainty: number;\n  feasibility: number;\n}\n\nconst EPSILON = 1e-10;\n\nexport function createActiveInferenceEngine(\n  config: ActiveInferenceConfig,\n): ActiveInferenceEngine {\n  // Validate model\n  if (\n    !config.model.states.length ||\n    !config.model.observations.length ||\n    !config.model.actions.length\n  ) {\n    throw new Error(\n      \"Invalid generative model: missing states, observations, or actions\",\n    );\n  }\n\n  if (Object.keys(config.model.transitionModel).length === 0) {\n    throw new Error(\"Invalid generative model: empty transition model\");\n  }\n\n  // Initialize uniform beliefs\n  const uniformProb = 1.0 / config.model.states.length;\n  const initialBeliefs: Beliefs = {\n    states: {},\n    uncertainty: 1.0,\n  };\n\n  config.model.states.forEach((state) => {\n    initialBeliefs.states[state] = uniformProb;\n  });\n\n  const engine: ActiveInferenceEngine = {\n    model: config.model,\n    precision: config.precision || 1.0,\n    learningRate: config.learningRate || 0.1,\n    planningHorizon: config.planningHorizon || 3,\n    actionConstraints: config.actionConstraints,\n    beliefs: initialBeliefs,\n    actionHistory: [],\n\n    getCurrentBeliefs: function () {\n      return { ...this.beliefs };\n    },\n\n    setBeliefs: function (beliefs: Beliefs) {\n      this.beliefs = { ...beliefs };\n    },\n\n    calculateFreeEnergy: function (beliefs: Beliefs, observation: string) {\n      // Accuracy term (expected log likelihood)\n      let accuracy = 0;\n      Object.entries(beliefs.states).forEach(([state, prob]) => {\n        const likelihood =\n          this.model.observationModel[state]?.[observation] || EPSILON;\n        accuracy += prob * Math.log(likelihood + EPSILON);\n      });\n\n      // Complexity term (KL divergence from prior)\n      let complexity = 0;\n      const prior = 1.0 / this.model.states.length;\n      Object.values(beliefs.states).forEach((prob) => {\n        if (prob > 0) {\n          complexity += prob * Math.log((prob + EPSILON) / prior);\n        }\n      });\n\n      // Convert preference to a positive cost term\n      // Negative preferences (rewards) become positive costs\n      const preference = this.model.preferences[observation] || 0;\n      const cost = -preference; // Convert reward to cost\n\n      // Add uncertainty term\n      const uncertaintyPenalty = beliefs.uncertainty * 2.0;\n\n      // Free energy = -log likelihood + complexity + cost + uncertainty\n      const freeEnergy = -accuracy + complexity + cost + uncertaintyPenalty;\n\n      // Ensure free energy is positive by adding a constant if needed\n      return Math.max(0.01, freeEnergy);\n    },\n  };\n\n  return engine;\n}\n\nexport function updateBeliefs(\n  engine: ActiveInferenceEngine,\n  observation: SensoryInput,\n): Beliefs {\n  const currentBeliefs = engine.getCurrentBeliefs();\n  const updatedBeliefs: Beliefs = {\n    states: {},\n    uncertainty: currentBeliefs.uncertainty,\n  };\n\n  // Standard Bayesian belief update\n  let totalPosterior = 0;\n\n  engine.model.states.forEach((state) => {\n    const prior = currentBeliefs.states[state];\n    const likelihood =\n      engine.model.observationModel[state]?.[observation.value] || EPSILON;\n\n    const posterior = prior * likelihood;\n    updatedBeliefs.states[state] = posterior;\n    totalPosterior += posterior;\n  });\n\n  // Normalize to get standard Bayesian posterior\n  Object.keys(updatedBeliefs.states).forEach((state) => {\n    updatedBeliefs.states[state] /= totalPosterior;\n  });\n\n  // Apply confidence weighting by interpolating between prior and posterior\n  Object.keys(updatedBeliefs.states).forEach((state) => {\n    const prior = currentBeliefs.states[state];\n    const posterior = updatedBeliefs.states[state];\n    \n    // High confidence = use more of posterior, low confidence = use more of prior\n    updatedBeliefs.states[state] = \n      observation.confidence * posterior + \n      (1 - observation.confidence) * prior;\n  });\n\n  // Update uncertainty based on observation confidence and belief entropy\n  const entropy = Object.values(updatedBeliefs.states).reduce((h, p) => {\n    return p > 0 ? h - p * Math.log(p + EPSILON) : h;\n  }, 0);\n\n  updatedBeliefs.uncertainty =\n    (1 - observation.confidence) * 0.3 + entropy * 0.7;\n\n  // Don't modify engine state, just return the updated beliefs\n  return updatedBeliefs;\n}\n\nexport function selectAction(\n  engine: ActiveInferenceEngine,\n  beliefs: Beliefs,\n): Action {\n  let bestAction = \"\";\n  let minExpectedFE = Infinity;\n  const actionScores: Record<string, number> = {};\n\n  // Check action constraints\n  const actionCounts: Record<string, number> = {};\n  engine.actionHistory.forEach((action) => {\n    actionCounts[action] = (actionCounts[action] || 0) + 1;\n  });\n\n  engine.model.actions.forEach((action) => {\n    // Check constraints\n    if (engine.actionConstraints?.[action]) {\n      const frequency =\n        (actionCounts[action] || 0) / Math.max(engine.actionHistory.length, 1);\n      if (frequency >= engine.actionConstraints[action].maxFrequency) {\n        actionScores[action] = Infinity;\n        return;\n      }\n    }\n\n    // Calculate expected free energy for this action\n    let expectedFE = 0;\n\n    // Epistemic value (information gain)\n    const epistemic = calculateEpistemic(engine, beliefs, action);\n\n    // Pragmatic value (goal achievement)\n    const pragmatic = calculatePragmatic(engine, beliefs, action);\n\n    // Combine with precision weighting\n    expectedFE = engine.precision * pragmatic - epistemic;\n\n    // Add exploration bonus under high uncertainty\n    if (beliefs.uncertainty > 0.5 && action !== \"wait\") {\n      expectedFE -= beliefs.uncertainty * 0.5;\n    }\n\n    // Add action variety bonus to prevent getting stuck\n    const recentActions = engine.actionHistory.slice(-5);\n    const actionFrequency = recentActions.filter(a => a === action).length / Math.max(recentActions.length, 1);\n    const varietyPenalty = actionFrequency * 2.0; // Penalize repetitive actions\n    expectedFE += varietyPenalty;\n\n    actionScores[action] = expectedFE;\n\n    if (expectedFE < minExpectedFE) {\n      minExpectedFE = expectedFE;\n      bestAction = action;\n    }\n  });\n\n  // Calculate action confidence based on score differences\n  const scores = Object.values(actionScores).filter((s) => s !== Infinity);\n  const avgScore = scores.reduce((a, b) => a + b, 0) / scores.length;\n  const confidence = Math.exp(-Math.abs(minExpectedFE - avgScore));\n\n  engine.actionHistory.push(bestAction);\n\n  return {\n    type: bestAction,\n    confidence: Math.min(Math.max(confidence, 0.1), 1.0),\n  };\n}\n\nexport async function performInference(\n  engine: ActiveInferenceEngine,\n  observation: SensoryInput,\n): Promise<InferenceResult> {\n  // Update beliefs based on observation\n  const updatedBeliefs = updateBeliefs(engine, observation);\n\n  // Update the engine's beliefs for persistence across inferences\n  engine.setBeliefs(updatedBeliefs);\n\n  // Calculate current free energy\n  const freeEnergy = engine.calculateFreeEnergy(\n    updatedBeliefs,\n    observation.value,\n  );\n\n  // Select action that minimizes expected free energy\n  const selectedAction = selectAction(engine, updatedBeliefs);\n\n  // Overall confidence based on belief certainty and action confidence\n  const beliefCertainty = Math.max(...Object.values(updatedBeliefs.states));\n  const overallConfidence = (beliefCertainty + selectedAction.confidence) / 2;\n\n  return {\n    beliefs: updatedBeliefs,\n    selectedAction,\n    freeEnergy,\n    confidence: overallConfidence,\n  };\n}\n\nexport function calculateExpectedFreeEnergy(\n  engine: ActiveInferenceEngine,\n  policy: Policy,\n): ExpectedFreeEnergy {\n  let totalEFE = 0;\n  let totalEpistemic = 0;\n  let totalPragmatic = 0;\n\n  // Start with current beliefs\n  let beliefs = engine.getCurrentBeliefs();\n\n  policy.forEach((step) => {\n    const epistemic = calculateEpistemic(engine, beliefs, step.action);\n    const pragmatic = calculatePragmatic(engine, beliefs, step.action);\n\n    // Ensure finite values\n    const finiteEpistemic = Number.isFinite(epistemic) ? epistemic : 0;\n    const finitePragmatic = Number.isFinite(pragmatic) ? pragmatic : 0;\n\n    totalEpistemic += finiteEpistemic * Math.pow(0.9, step.timestep); // Discount future\n    totalPragmatic += finitePragmatic * Math.pow(0.9, step.timestep);\n\n    // Predict belief evolution\n    beliefs = predictBeliefEvolution(engine, beliefs, step.action);\n  });\n\n  totalEFE = engine.precision * totalPragmatic - totalEpistemic;\n\n  // Ensure all values are finite\n  return {\n    total: Number.isFinite(totalEFE) ? totalEFE : 0,\n    epistemic: Number.isFinite(totalEpistemic) ? totalEpistemic : 0,\n    pragmatic: Number.isFinite(totalPragmatic) ? totalPragmatic : 0,\n  };\n}\n\nexport function calculateEpistemic(\n  engine: ActiveInferenceEngine,\n  beliefs: Beliefs,\n  action: string,\n): number {\n  // Information gain: reduction in uncertainty about states\n  let informationGain = 0;\n\n  // Current entropy\n  const currentEntropy = Object.values(beliefs.states).reduce((h, p) => {\n    return p > 0 ? h - p * Math.log(p + EPSILON) : h;\n  }, 0);\n\n  // Expected entropy after action\n  let expectedEntropy = 0;\n  const predictedBeliefs = predictBeliefEvolution(engine, beliefs, action);\n\n  expectedEntropy = Object.values(predictedBeliefs.states).reduce((h, p) => {\n    return p > 0 ? h - p * Math.log(p + EPSILON) : h;\n  }, 0);\n\n  informationGain = currentEntropy - expectedEntropy;\n\n  // Add exploration bonus for uncertain states\n  const explorationBonus = beliefs.uncertainty * 0.3;\n\n  const result = Math.max(0, informationGain + explorationBonus);\n  \n  // Ensure finite result\n  return Number.isFinite(result) ? result : 0;\n}\n\nexport function calculatePragmatic(\n  engine: ActiveInferenceEngine,\n  beliefs: Beliefs,\n  action: string,\n): number {\n  // Expected preference satisfaction\n  let expectedPreference = 0;\n\n  // Predict outcomes for this action\n  const predictions = predictSensoryOutcomes(engine, beliefs, action);\n\n  Object.entries(predictions).forEach(([outcome, prob]) => {\n    const preference = engine.model.preferences[outcome] || 0;\n    const contribution = prob * preference;\n    \n    // Only add finite contributions\n    if (Number.isFinite(contribution)) {\n      expectedPreference += contribution;\n    }\n  });\n\n  // Ensure finite result\n  return Number.isFinite(expectedPreference) ? expectedPreference : 0;\n}\n\nexport async function minimizeVariationalFreeEnergy(\n  engine: ActiveInferenceEngine,\n  initialBeliefs: Beliefs,\n  observation: string,\n  options?: { maxIterations?: number; tolerance?: number },\n): Promise<Beliefs> {\n  const maxIter = options?.maxIterations || 100;\n  const tolerance = options?.tolerance || 0.001;\n\n  let beliefs = { ...initialBeliefs };\n  let prevFE = engine.calculateFreeEnergy(beliefs, observation);\n  let converged = false;\n  let iterations = 0;\n\n  while (iterations < maxIter && !converged) {\n    // Gradient descent on beliefs\n    const gradient: Record<string, number> = {};\n    const delta = 0.001;\n\n    engine.model.states.forEach((state) => {\n      // Finite difference approximation\n      const beliefsCopy = { ...beliefs };\n      beliefsCopy.states[state] = Math.min(beliefs.states[state] + delta, 1);\n\n      // Renormalize\n      const sum = Object.values(beliefsCopy.states).reduce((s, p) => s + p, 0);\n      Object.keys(beliefsCopy.states).forEach((s) => {\n        beliefsCopy.states[s] /= sum;\n      });\n\n      const fePlus = engine.calculateFreeEnergy(beliefsCopy, observation);\n      gradient[state] = (fePlus - prevFE) / delta;\n    });\n\n    // Update beliefs\n    let changed = false;\n    engine.model.states.forEach((state) => {\n      const update = -gradient[state] * engine.learningRate;\n      const newBelief = Math.max(\n        0,\n        Math.min(1, beliefs.states[state] + update),\n      );\n\n      if (Math.abs(newBelief - beliefs.states[state]) > tolerance) {\n        changed = true;\n      }\n\n      beliefs.states[state] = newBelief;\n    });\n\n    // Renormalize\n    const sum = Object.values(beliefs.states).reduce((s, p) => s + p, 0);\n    Object.keys(beliefs.states).forEach((state) => {\n      beliefs.states[state] /= sum;\n    });\n\n    // Check convergence\n    const currentFE = engine.calculateFreeEnergy(beliefs, observation);\n    if (!changed || Math.abs(currentFE - prevFE) < tolerance) {\n      converged = true;\n    }\n\n    prevFE = currentFE;\n    iterations++;\n  }\n\n  return {\n    ...beliefs,\n    converged,\n    iterations,\n  };\n}\n\nexport function predictSensoryOutcomes(\n  engine: ActiveInferenceEngine,\n  beliefs: Beliefs,\n  action: string,\n): Record<string, number> {\n  const predictions: Record<string, number> = {};\n\n  // Initialize predictions\n  engine.model.observations.forEach((obs) => {\n    predictions[obs] = 0;\n  });\n\n  // For each current state\n  Object.entries(beliefs.states).forEach(([currentState, stateProb]) => {\n    // Get transition probabilities for this action\n    const transitions =\n      engine.model.transitionModel[currentState]?.[action] || {};\n\n    // For each possible next state\n    Object.entries(transitions).forEach(([nextState, transProb]) => {\n      // Get observation probabilities for next state\n      const observations = engine.model.observationModel[nextState] || {};\n\n      // Accumulate prediction\n      Object.entries(observations).forEach(([obs, obsProb]) => {\n        predictions[obs] += stateProb * transProb * obsProb;\n      });\n    });\n  });\n\n  return predictions;\n}\n\nexport function evaluateActionPolicy(\n  engine: ActiveInferenceEngine,\n  policy: Policy,\n): PolicyEvaluation {\n  let expectedReturn = 0;\n  let totalUncertainty = 0;\n  let feasibility = 1.0;\n\n  let beliefs = engine.getCurrentBeliefs();\n\n  policy.forEach((step, t) => {\n    // Expected immediate reward\n    const predictions = predictSensoryOutcomes(engine, beliefs, step.action);\n    const immediateReturn = Object.entries(predictions).reduce(\n      (sum, [outcome, prob]) => {\n        const preference = engine.model.preferences[outcome] || 0;\n        return sum - prob * preference; // Negative because lower is better\n      },\n      0,\n    );\n\n    expectedReturn += immediateReturn * Math.pow(0.9, t);\n\n    // Accumulate uncertainty\n    totalUncertainty += beliefs.uncertainty * Math.pow(0.9, t);\n\n    // Check action feasibility\n    if (!engine.model.actions.includes(step.action)) {\n      feasibility *= 0.1;\n    }\n\n    // Evolve beliefs\n    beliefs = predictBeliefEvolution(engine, beliefs, step.action);\n  });\n\n  return {\n    expectedReturn,\n    uncertainty: totalUncertainty / policy.length,\n    feasibility,\n  };\n}\n\n// Helper function to predict belief evolution\nfunction predictBeliefEvolution(\n  engine: ActiveInferenceEngine,\n  beliefs: Beliefs,\n  action: string,\n): Beliefs {\n  const evolved: Beliefs = {\n    states: {},\n    uncertainty: beliefs.uncertainty,\n  };\n\n  // Initialize\n  engine.model.states.forEach((state) => {\n    evolved.states[state] = 0;\n  });\n\n  // Predict state evolution\n  Object.entries(beliefs.states).forEach(([currentState, prob]) => {\n    const transitions =\n      engine.model.transitionModel[currentState]?.[action] || {};\n\n    Object.entries(transitions).forEach(([nextState, transProb]) => {\n      evolved.states[nextState] += prob * transProb;\n    });\n  });\n\n  // Update uncertainty (tends to increase without observations)\n  evolved.uncertainty = Math.min(1.0, beliefs.uncertainty * 1.1);\n\n  return evolved;\n}\n"],"names":["calculateEpistemic","calculateExpectedFreeEnergy","calculatePragmatic","createActiveInferenceEngine","evaluateActionPolicy","minimizeVariationalFreeEnergy","performInference","predictSensoryOutcomes","selectAction","updateBeliefs","EPSILON","config","model","states","length","observations","actions","Error","Object","keys","transitionModel","uniformProb","initialBeliefs","uncertainty","forEach","state","engine","precision","learningRate","planningHorizon","actionConstraints","beliefs","actionHistory","getCurrentBeliefs","setBeliefs","calculateFreeEnergy","observation","accuracy","entries","prob","likelihood","observationModel","Math","log","complexity","prior","values","preference","preferences","cost","uncertaintyPenalty","freeEnergy","max","currentBeliefs","updatedBeliefs","totalPosterior","value","posterior","confidence","entropy","reduce","h","p","bestAction","minExpectedFE","Infinity","actionScores","actionCounts","action","frequency","maxFrequency","expectedFE","epistemic","pragmatic","recentActions","slice","actionFrequency","filter","a","varietyPenalty","scores","s","avgScore","b","exp","abs","push","type","min","selectedAction","beliefCertainty","overallConfidence","policy","totalEFE","totalEpistemic","totalPragmatic","step","finiteEpistemic","Number","isFinite","finitePragmatic","pow","timestep","predictBeliefEvolution","total","informationGain","currentEntropy","expectedEntropy","predictedBeliefs","explorationBonus","result","expectedPreference","predictions","outcome","contribution","options","maxIter","maxIterations","tolerance","prevFE","converged","iterations","gradient","delta","beliefsCopy","sum","fePlus","changed","update","newBelief","currentFE","obs","currentState","stateProb","transitions","nextState","transProb","obsProb","expectedReturn","totalUncertainty","feasibility","t","immediateReturn","includes","evolved"],"mappings":"AAAA;;;;;CAKC;;;;;;;;;;;IA2VeA,kBAAkB;eAAlBA;;IApCAC,2BAA2B;eAA3BA;;IAoEAC,kBAAkB;eAAlBA;;IA9SAC,2BAA2B;eAA3BA;;IAibAC,oBAAoB;eAApBA;;IA1GMC,6BAA6B;eAA7BA;;IA5HAC,gBAAgB;eAAhBA;;IAqMNC,sBAAsB;eAAtBA;;IA1QAC,YAAY;eAAZA;;IAnDAC,aAAa;eAAbA;;;AArFhB,MAAMC,UAAU;AAET,SAASP,4BACdQ,MAA6B;IAE7B,iBAAiB;IACjB,IACE,CAACA,OAAOC,KAAK,CAACC,MAAM,CAACC,MAAM,IAC3B,CAACH,OAAOC,KAAK,CAACG,YAAY,CAACD,MAAM,IACjC,CAACH,OAAOC,KAAK,CAACI,OAAO,CAACF,MAAM,EAC5B;QACA,MAAM,IAAIG,MACR;IAEJ;IAEA,IAAIC,OAAOC,IAAI,CAACR,OAAOC,KAAK,CAACQ,eAAe,EAAEN,MAAM,KAAK,GAAG;QAC1D,MAAM,IAAIG,MAAM;IAClB;IAEA,6BAA6B;IAC7B,MAAMI,cAAc,MAAMV,OAAOC,KAAK,CAACC,MAAM,CAACC,MAAM;IACpD,MAAMQ,iBAA0B;QAC9BT,QAAQ,CAAC;QACTU,aAAa;IACf;IAEAZ,OAAOC,KAAK,CAACC,MAAM,CAACW,OAAO,CAAC,CAACC;QAC3BH,eAAeT,MAAM,CAACY,MAAM,GAAGJ;IACjC;IAEA,MAAMK,SAAgC;QACpCd,OAAOD,OAAOC,KAAK;QACnBe,WAAWhB,OAAOgB,SAAS,IAAI;QAC/BC,cAAcjB,OAAOiB,YAAY,IAAI;QACrCC,iBAAiBlB,OAAOkB,eAAe,IAAI;QAC3CC,mBAAmBnB,OAAOmB,iBAAiB;QAC3CC,SAAST;QACTU,eAAe,EAAE;QAEjBC,mBAAmB;YACjB,OAAO;gBAAE,GAAG,IAAI,CAACF,OAAO;YAAC;QAC3B;QAEAG,YAAY,SAAUH,OAAgB;YACpC,IAAI,CAACA,OAAO,GAAG;gBAAE,GAAGA,OAAO;YAAC;QAC9B;QAEAI,qBAAqB,SAAUJ,OAAgB,EAAEK,WAAmB;YAClE,0CAA0C;YAC1C,IAAIC,WAAW;YACfnB,OAAOoB,OAAO,CAACP,QAAQlB,MAAM,EAAEW,OAAO,CAAC,CAAC,CAACC,OAAOc,KAAK;gBACnD,MAAMC,aACJ,IAAI,CAAC5B,KAAK,CAAC6B,gBAAgB,CAAChB,MAAM,EAAE,CAACW,YAAY,IAAI1B;gBACvD2B,YAAYE,OAAOG,KAAKC,GAAG,CAACH,aAAa9B;YAC3C;YAEA,6CAA6C;YAC7C,IAAIkC,aAAa;YACjB,MAAMC,QAAQ,MAAM,IAAI,CAACjC,KAAK,CAACC,MAAM,CAACC,MAAM;YAC5CI,OAAO4B,MAAM,CAACf,QAAQlB,MAAM,EAAEW,OAAO,CAAC,CAACe;gBACrC,IAAIA,OAAO,GAAG;oBACZK,cAAcL,OAAOG,KAAKC,GAAG,CAAC,AAACJ,CAAAA,OAAO7B,OAAM,IAAKmC;gBACnD;YACF;YAEA,6CAA6C;YAC7C,uDAAuD;YACvD,MAAME,aAAa,IAAI,CAACnC,KAAK,CAACoC,WAAW,CAACZ,YAAY,IAAI;YAC1D,MAAMa,OAAO,CAACF,YAAY,yBAAyB;YAEnD,uBAAuB;YACvB,MAAMG,qBAAqBnB,QAAQR,WAAW,GAAG;YAEjD,kEAAkE;YAClE,MAAM4B,aAAa,CAACd,WAAWO,aAAaK,OAAOC;YAEnD,gEAAgE;YAChE,OAAOR,KAAKU,GAAG,CAAC,MAAMD;QACxB;IACF;IAEA,OAAOzB;AACT;AAEO,SAASjB,cACdiB,MAA6B,EAC7BU,WAAyB;IAEzB,MAAMiB,iBAAiB3B,OAAOO,iBAAiB;IAC/C,MAAMqB,iBAA0B;QAC9BzC,QAAQ,CAAC;QACTU,aAAa8B,eAAe9B,WAAW;IACzC;IAEA,kCAAkC;IAClC,IAAIgC,iBAAiB;IAErB7B,OAAOd,KAAK,CAACC,MAAM,CAACW,OAAO,CAAC,CAACC;QAC3B,MAAMoB,QAAQQ,eAAexC,MAAM,CAACY,MAAM;QAC1C,MAAMe,aACJd,OAAOd,KAAK,CAAC6B,gBAAgB,CAAChB,MAAM,EAAE,CAACW,YAAYoB,KAAK,CAAC,IAAI9C;QAE/D,MAAM+C,YAAYZ,QAAQL;QAC1Bc,eAAezC,MAAM,CAACY,MAAM,GAAGgC;QAC/BF,kBAAkBE;IACpB;IAEA,+CAA+C;IAC/CvC,OAAOC,IAAI,CAACmC,eAAezC,MAAM,EAAEW,OAAO,CAAC,CAACC;QAC1C6B,eAAezC,MAAM,CAACY,MAAM,IAAI8B;IAClC;IAEA,0EAA0E;IAC1ErC,OAAOC,IAAI,CAACmC,eAAezC,MAAM,EAAEW,OAAO,CAAC,CAACC;QAC1C,MAAMoB,QAAQQ,eAAexC,MAAM,CAACY,MAAM;QAC1C,MAAMgC,YAAYH,eAAezC,MAAM,CAACY,MAAM;QAE9C,8EAA8E;QAC9E6B,eAAezC,MAAM,CAACY,MAAM,GAC1BW,YAAYsB,UAAU,GAAGD,YACzB,AAAC,CAAA,IAAIrB,YAAYsB,UAAU,AAAD,IAAKb;IACnC;IAEA,wEAAwE;IACxE,MAAMc,UAAUzC,OAAO4B,MAAM,CAACQ,eAAezC,MAAM,EAAE+C,MAAM,CAAC,CAACC,GAAGC;QAC9D,OAAOA,IAAI,IAAID,IAAIC,IAAIpB,KAAKC,GAAG,CAACmB,IAAIpD,WAAWmD;IACjD,GAAG;IAEHP,eAAe/B,WAAW,GACxB,AAAC,CAAA,IAAIa,YAAYsB,UAAU,AAAD,IAAK,MAAMC,UAAU;IAEjD,6DAA6D;IAC7D,OAAOL;AACT;AAEO,SAAS9C,aACdkB,MAA6B,EAC7BK,OAAgB;IAEhB,IAAIgC,aAAa;IACjB,IAAIC,gBAAgBC;IACpB,MAAMC,eAAuC,CAAC;IAE9C,2BAA2B;IAC3B,MAAMC,eAAuC,CAAC;IAC9CzC,OAAOM,aAAa,CAACR,OAAO,CAAC,CAAC4C;QAC5BD,YAAY,CAACC,OAAO,GAAG,AAACD,CAAAA,YAAY,CAACC,OAAO,IAAI,CAAA,IAAK;IACvD;IAEA1C,OAAOd,KAAK,CAACI,OAAO,CAACQ,OAAO,CAAC,CAAC4C;QAC5B,oBAAoB;QACpB,IAAI1C,OAAOI,iBAAiB,EAAE,CAACsC,OAAO,EAAE;YACtC,MAAMC,YACJ,AAACF,CAAAA,YAAY,CAACC,OAAO,IAAI,CAAA,IAAK1B,KAAKU,GAAG,CAAC1B,OAAOM,aAAa,CAAClB,MAAM,EAAE;YACtE,IAAIuD,aAAa3C,OAAOI,iBAAiB,CAACsC,OAAO,CAACE,YAAY,EAAE;gBAC9DJ,YAAY,CAACE,OAAO,GAAGH;gBACvB;YACF;QACF;QAEA,iDAAiD;QACjD,IAAIM,aAAa;QAEjB,qCAAqC;QACrC,MAAMC,YAAYxE,mBAAmB0B,QAAQK,SAASqC;QAEtD,qCAAqC;QACrC,MAAMK,YAAYvE,mBAAmBwB,QAAQK,SAASqC;QAEtD,mCAAmC;QACnCG,aAAa7C,OAAOC,SAAS,GAAG8C,YAAYD;QAE5C,+CAA+C;QAC/C,IAAIzC,QAAQR,WAAW,GAAG,OAAO6C,WAAW,QAAQ;YAClDG,cAAcxC,QAAQR,WAAW,GAAG;QACtC;QAEA,oDAAoD;QACpD,MAAMmD,gBAAgBhD,OAAOM,aAAa,CAAC2C,KAAK,CAAC,CAAC;QAClD,MAAMC,kBAAkBF,cAAcG,MAAM,CAACC,CAAAA,IAAKA,MAAMV,QAAQtD,MAAM,GAAG4B,KAAKU,GAAG,CAACsB,cAAc5D,MAAM,EAAE;QACxG,MAAMiE,iBAAiBH,kBAAkB,KAAK,8BAA8B;QAC5EL,cAAcQ;QAEdb,YAAY,CAACE,OAAO,GAAGG;QAEvB,IAAIA,aAAaP,eAAe;YAC9BA,gBAAgBO;YAChBR,aAAaK;QACf;IACF;IAEA,yDAAyD;IACzD,MAAMY,SAAS9D,OAAO4B,MAAM,CAACoB,cAAcW,MAAM,CAAC,CAACI,IAAMA,MAAMhB;IAC/D,MAAMiB,WAAWF,OAAOpB,MAAM,CAAC,CAACkB,GAAGK,IAAML,IAAIK,GAAG,KAAKH,OAAOlE,MAAM;IAClE,MAAM4C,aAAahB,KAAK0C,GAAG,CAAC,CAAC1C,KAAK2C,GAAG,CAACrB,gBAAgBkB;IAEtDxD,OAAOM,aAAa,CAACsD,IAAI,CAACvB;IAE1B,OAAO;QACLwB,MAAMxB;QACNL,YAAYhB,KAAK8C,GAAG,CAAC9C,KAAKU,GAAG,CAACM,YAAY,MAAM;IAClD;AACF;AAEO,eAAepD,iBACpBoB,MAA6B,EAC7BU,WAAyB;IAEzB,sCAAsC;IACtC,MAAMkB,iBAAiB7C,cAAciB,QAAQU;IAE7C,gEAAgE;IAChEV,OAAOQ,UAAU,CAACoB;IAElB,gCAAgC;IAChC,MAAMH,aAAazB,OAAOS,mBAAmB,CAC3CmB,gBACAlB,YAAYoB,KAAK;IAGnB,oDAAoD;IACpD,MAAMiC,iBAAiBjF,aAAakB,QAAQ4B;IAE5C,qEAAqE;IACrE,MAAMoC,kBAAkBhD,KAAKU,GAAG,IAAIlC,OAAO4B,MAAM,CAACQ,eAAezC,MAAM;IACvE,MAAM8E,oBAAoB,AAACD,CAAAA,kBAAkBD,eAAe/B,UAAU,AAAD,IAAK;IAE1E,OAAO;QACL3B,SAASuB;QACTmC;QACAtC;QACAO,YAAYiC;IACd;AACF;AAEO,SAAS1F,4BACdyB,MAA6B,EAC7BkE,MAAc;IAEd,IAAIC,WAAW;IACf,IAAIC,iBAAiB;IACrB,IAAIC,iBAAiB;IAErB,6BAA6B;IAC7B,IAAIhE,UAAUL,OAAOO,iBAAiB;IAEtC2D,OAAOpE,OAAO,CAAC,CAACwE;QACd,MAAMxB,YAAYxE,mBAAmB0B,QAAQK,SAASiE,KAAK5B,MAAM;QACjE,MAAMK,YAAYvE,mBAAmBwB,QAAQK,SAASiE,KAAK5B,MAAM;QAEjE,uBAAuB;QACvB,MAAM6B,kBAAkBC,OAAOC,QAAQ,CAAC3B,aAAaA,YAAY;QACjE,MAAM4B,kBAAkBF,OAAOC,QAAQ,CAAC1B,aAAaA,YAAY;QAEjEqB,kBAAkBG,kBAAkBvD,KAAK2D,GAAG,CAAC,KAAKL,KAAKM,QAAQ,GAAG,kBAAkB;QACpFP,kBAAkBK,kBAAkB1D,KAAK2D,GAAG,CAAC,KAAKL,KAAKM,QAAQ;QAE/D,2BAA2B;QAC3BvE,UAAUwE,uBAAuB7E,QAAQK,SAASiE,KAAK5B,MAAM;IAC/D;IAEAyB,WAAWnE,OAAOC,SAAS,GAAGoE,iBAAiBD;IAE/C,+BAA+B;IAC/B,OAAO;QACLU,OAAON,OAAOC,QAAQ,CAACN,YAAYA,WAAW;QAC9CrB,WAAW0B,OAAOC,QAAQ,CAACL,kBAAkBA,iBAAiB;QAC9DrB,WAAWyB,OAAOC,QAAQ,CAACJ,kBAAkBA,iBAAiB;IAChE;AACF;AAEO,SAAS/F,mBACd0B,MAA6B,EAC7BK,OAAgB,EAChBqC,MAAc;IAEd,0DAA0D;IAC1D,IAAIqC,kBAAkB;IAEtB,kBAAkB;IAClB,MAAMC,iBAAiBxF,OAAO4B,MAAM,CAACf,QAAQlB,MAAM,EAAE+C,MAAM,CAAC,CAACC,GAAGC;QAC9D,OAAOA,IAAI,IAAID,IAAIC,IAAIpB,KAAKC,GAAG,CAACmB,IAAIpD,WAAWmD;IACjD,GAAG;IAEH,gCAAgC;IAChC,IAAI8C,kBAAkB;IACtB,MAAMC,mBAAmBL,uBAAuB7E,QAAQK,SAASqC;IAEjEuC,kBAAkBzF,OAAO4B,MAAM,CAAC8D,iBAAiB/F,MAAM,EAAE+C,MAAM,CAAC,CAACC,GAAGC;QAClE,OAAOA,IAAI,IAAID,IAAIC,IAAIpB,KAAKC,GAAG,CAACmB,IAAIpD,WAAWmD;IACjD,GAAG;IAEH4C,kBAAkBC,iBAAiBC;IAEnC,6CAA6C;IAC7C,MAAME,mBAAmB9E,QAAQR,WAAW,GAAG;IAE/C,MAAMuF,SAASpE,KAAKU,GAAG,CAAC,GAAGqD,kBAAkBI;IAE7C,uBAAuB;IACvB,OAAOX,OAAOC,QAAQ,CAACW,UAAUA,SAAS;AAC5C;AAEO,SAAS5G,mBACdwB,MAA6B,EAC7BK,OAAgB,EAChBqC,MAAc;IAEd,mCAAmC;IACnC,IAAI2C,qBAAqB;IAEzB,mCAAmC;IACnC,MAAMC,cAAczG,uBAAuBmB,QAAQK,SAASqC;IAE5DlD,OAAOoB,OAAO,CAAC0E,aAAaxF,OAAO,CAAC,CAAC,CAACyF,SAAS1E,KAAK;QAClD,MAAMQ,aAAarB,OAAOd,KAAK,CAACoC,WAAW,CAACiE,QAAQ,IAAI;QACxD,MAAMC,eAAe3E,OAAOQ;QAE5B,gCAAgC;QAChC,IAAImD,OAAOC,QAAQ,CAACe,eAAe;YACjCH,sBAAsBG;QACxB;IACF;IAEA,uBAAuB;IACvB,OAAOhB,OAAOC,QAAQ,CAACY,sBAAsBA,qBAAqB;AACpE;AAEO,eAAe1G,8BACpBqB,MAA6B,EAC7BJ,cAAuB,EACvBc,WAAmB,EACnB+E,OAAwD;IAExD,MAAMC,UAAUD,SAASE,iBAAiB;IAC1C,MAAMC,YAAYH,SAASG,aAAa;IAExC,IAAIvF,UAAU;QAAE,GAAGT,cAAc;IAAC;IAClC,IAAIiG,SAAS7F,OAAOS,mBAAmB,CAACJ,SAASK;IACjD,IAAIoF,YAAY;IAChB,IAAIC,aAAa;IAEjB,MAAOA,aAAaL,WAAW,CAACI,UAAW;QACzC,8BAA8B;QAC9B,MAAME,WAAmC,CAAC;QAC1C,MAAMC,QAAQ;QAEdjG,OAAOd,KAAK,CAACC,MAAM,CAACW,OAAO,CAAC,CAACC;YAC3B,kCAAkC;YAClC,MAAMmG,cAAc;gBAAE,GAAG7F,OAAO;YAAC;YACjC6F,YAAY/G,MAAM,CAACY,MAAM,GAAGiB,KAAK8C,GAAG,CAACzD,QAAQlB,MAAM,CAACY,MAAM,GAAGkG,OAAO;YAEpE,cAAc;YACd,MAAME,MAAM3G,OAAO4B,MAAM,CAAC8E,YAAY/G,MAAM,EAAE+C,MAAM,CAAC,CAACqB,GAAGnB,IAAMmB,IAAInB,GAAG;YACtE5C,OAAOC,IAAI,CAACyG,YAAY/G,MAAM,EAAEW,OAAO,CAAC,CAACyD;gBACvC2C,YAAY/G,MAAM,CAACoE,EAAE,IAAI4C;YAC3B;YAEA,MAAMC,SAASpG,OAAOS,mBAAmB,CAACyF,aAAaxF;YACvDsF,QAAQ,CAACjG,MAAM,GAAG,AAACqG,CAAAA,SAASP,MAAK,IAAKI;QACxC;QAEA,iBAAiB;QACjB,IAAII,UAAU;QACdrG,OAAOd,KAAK,CAACC,MAAM,CAACW,OAAO,CAAC,CAACC;YAC3B,MAAMuG,SAAS,CAACN,QAAQ,CAACjG,MAAM,GAAGC,OAAOE,YAAY;YACrD,MAAMqG,YAAYvF,KAAKU,GAAG,CACxB,GACAV,KAAK8C,GAAG,CAAC,GAAGzD,QAAQlB,MAAM,CAACY,MAAM,GAAGuG;YAGtC,IAAItF,KAAK2C,GAAG,CAAC4C,YAAYlG,QAAQlB,MAAM,CAACY,MAAM,IAAI6F,WAAW;gBAC3DS,UAAU;YACZ;YAEAhG,QAAQlB,MAAM,CAACY,MAAM,GAAGwG;QAC1B;QAEA,cAAc;QACd,MAAMJ,MAAM3G,OAAO4B,MAAM,CAACf,QAAQlB,MAAM,EAAE+C,MAAM,CAAC,CAACqB,GAAGnB,IAAMmB,IAAInB,GAAG;QAClE5C,OAAOC,IAAI,CAACY,QAAQlB,MAAM,EAAEW,OAAO,CAAC,CAACC;YACnCM,QAAQlB,MAAM,CAACY,MAAM,IAAIoG;QAC3B;QAEA,oBAAoB;QACpB,MAAMK,YAAYxG,OAAOS,mBAAmB,CAACJ,SAASK;QACtD,IAAI,CAAC2F,WAAWrF,KAAK2C,GAAG,CAAC6C,YAAYX,UAAUD,WAAW;YACxDE,YAAY;QACd;QAEAD,SAASW;QACTT;IACF;IAEA,OAAO;QACL,GAAG1F,OAAO;QACVyF;QACAC;IACF;AACF;AAEO,SAASlH,uBACdmB,MAA6B,EAC7BK,OAAgB,EAChBqC,MAAc;IAEd,MAAM4C,cAAsC,CAAC;IAE7C,yBAAyB;IACzBtF,OAAOd,KAAK,CAACG,YAAY,CAACS,OAAO,CAAC,CAAC2G;QACjCnB,WAAW,CAACmB,IAAI,GAAG;IACrB;IAEA,yBAAyB;IACzBjH,OAAOoB,OAAO,CAACP,QAAQlB,MAAM,EAAEW,OAAO,CAAC,CAAC,CAAC4G,cAAcC,UAAU;QAC/D,+CAA+C;QAC/C,MAAMC,cACJ5G,OAAOd,KAAK,CAACQ,eAAe,CAACgH,aAAa,EAAE,CAAChE,OAAO,IAAI,CAAC;QAE3D,+BAA+B;QAC/BlD,OAAOoB,OAAO,CAACgG,aAAa9G,OAAO,CAAC,CAAC,CAAC+G,WAAWC,UAAU;YACzD,+CAA+C;YAC/C,MAAMzH,eAAeW,OAAOd,KAAK,CAAC6B,gBAAgB,CAAC8F,UAAU,IAAI,CAAC;YAElE,wBAAwB;YACxBrH,OAAOoB,OAAO,CAACvB,cAAcS,OAAO,CAAC,CAAC,CAAC2G,KAAKM,QAAQ;gBAClDzB,WAAW,CAACmB,IAAI,IAAIE,YAAYG,YAAYC;YAC9C;QACF;IACF;IAEA,OAAOzB;AACT;AAEO,SAAS5G,qBACdsB,MAA6B,EAC7BkE,MAAc;IAEd,IAAI8C,iBAAiB;IACrB,IAAIC,mBAAmB;IACvB,IAAIC,cAAc;IAElB,IAAI7G,UAAUL,OAAOO,iBAAiB;IAEtC2D,OAAOpE,OAAO,CAAC,CAACwE,MAAM6C;QACpB,4BAA4B;QAC5B,MAAM7B,cAAczG,uBAAuBmB,QAAQK,SAASiE,KAAK5B,MAAM;QACvE,MAAM0E,kBAAkB5H,OAAOoB,OAAO,CAAC0E,aAAapD,MAAM,CACxD,CAACiE,KAAK,CAACZ,SAAS1E,KAAK;YACnB,MAAMQ,aAAarB,OAAOd,KAAK,CAACoC,WAAW,CAACiE,QAAQ,IAAI;YACxD,OAAOY,MAAMtF,OAAOQ,YAAY,mCAAmC;QACrE,GACA;QAGF2F,kBAAkBI,kBAAkBpG,KAAK2D,GAAG,CAAC,KAAKwC;QAElD,yBAAyB;QACzBF,oBAAoB5G,QAAQR,WAAW,GAAGmB,KAAK2D,GAAG,CAAC,KAAKwC;QAExD,2BAA2B;QAC3B,IAAI,CAACnH,OAAOd,KAAK,CAACI,OAAO,CAAC+H,QAAQ,CAAC/C,KAAK5B,MAAM,GAAG;YAC/CwE,eAAe;QACjB;QAEA,iBAAiB;QACjB7G,UAAUwE,uBAAuB7E,QAAQK,SAASiE,KAAK5B,MAAM;IAC/D;IAEA,OAAO;QACLsE;QACAnH,aAAaoH,mBAAmB/C,OAAO9E,MAAM;QAC7C8H;IACF;AACF;AAEA,8CAA8C;AAC9C,SAASrC,uBACP7E,MAA6B,EAC7BK,OAAgB,EAChBqC,MAAc;IAEd,MAAM4E,UAAmB;QACvBnI,QAAQ,CAAC;QACTU,aAAaQ,QAAQR,WAAW;IAClC;IAEA,aAAa;IACbG,OAAOd,KAAK,CAACC,MAAM,CAACW,OAAO,CAAC,CAACC;QAC3BuH,QAAQnI,MAAM,CAACY,MAAM,GAAG;IAC1B;IAEA,0BAA0B;IAC1BP,OAAOoB,OAAO,CAACP,QAAQlB,MAAM,EAAEW,OAAO,CAAC,CAAC,CAAC4G,cAAc7F,KAAK;QAC1D,MAAM+F,cACJ5G,OAAOd,KAAK,CAACQ,eAAe,CAACgH,aAAa,EAAE,CAAChE,OAAO,IAAI,CAAC;QAE3DlD,OAAOoB,OAAO,CAACgG,aAAa9G,OAAO,CAAC,CAAC,CAAC+G,WAAWC,UAAU;YACzDQ,QAAQnI,MAAM,CAAC0H,UAAU,IAAIhG,OAAOiG;QACtC;IACF;IAEA,8DAA8D;IAC9DQ,QAAQzH,WAAW,GAAGmB,KAAK8C,GAAG,CAAC,KAAKzD,QAAQR,WAAW,GAAG;IAE1D,OAAOyH;AACT"}