[tool:pytest]
# Basic pytest configuration for test reporting and metrics
minversion = 6.0
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Test discovery patterns
addopts =
    # Coverage options
    --cov=.
    --cov-report=html:tests/reporting/coverage_html
    --cov-report=xml:tests/reporting/coverage.xml
    --cov-report=term-missing
    --cov-branch
    --cov-fail-under=70

    # Output options
    -v
    --tb=short
    --strict-markers
    --strict-config

    # Reporting options
    --generate-reports
    --junitxml=tests/reporting/junit.xml

    # Performance options
    --durations=10
    --durations-min=1.0

    # Warnings
    -W ignore::DeprecationWarning
    -W ignore::PendingDeprecationWarning

# Test markers
markers =
    slow: marks tests as slow (deselect with '-m "not slow"')
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    e2e: marks tests as end-to-end tests
    flaky: marks tests as potentially flaky
    critical: marks tests as critical for system functionality
    performance: marks tests as performance tests
    smoke: marks tests as smoke tests
    security: marks tests as security tests
    regression: marks tests as regression tests
    skip_on_ci: marks tests to skip on CI
    requires_docker: marks tests that require Docker
    requires_gpu: marks tests that require GPU
    requires_network: marks tests that require network access

# Logging configuration
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

log_file = tests/reporting/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] %(name)s: %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Filterwarnings
filterwarnings =
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::RuntimeWarning:torch.*
    ignore::FutureWarning:transformers.*
    error::UserWarning:tests.*

# Test timeout
timeout = 300
timeout_method = thread

# Parallel execution
# -n auto to run tests in parallel (requires pytest-xdist)
# Uncomment the following line to enable parallel execution:
# addopts = -n auto

# Plugin configuration
plugins =
    tests.reporting.pytest_metrics_plugin

# Coverage configuration
[coverage:run]
source = .
omit =
    */tests/*
    */venv/*
    */build/*
    */dist/*
    setup.py
    conftest.py
    */migrations/*
    */node_modules/*
    */__pycache__/*

branch = true
parallel = true

[coverage:report]
precision = 2
show_missing = true
skip_covered = false
skip_empty = true
sort = -cover

exclude_lines =

    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.:
    class .*\(Protocol\):
    @abstract

[coverage:html]
directory = tests/reporting/coverage_html
title = FreeAgentics Coverage Report

[coverage:xml]
output = tests/reporting/coverage.xml
